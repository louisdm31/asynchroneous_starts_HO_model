\documentclass{article}
\usepackage{amsmath}
\usepackage[noend]{sources-Heard-Of/distribalgo}
\usepackage{algorithm}
\usepackage{amssymb}
\usepackage{listings}
\usepackage{amsthm}
\usepackage{dsfont}
\usepackage{stmaryrd}
\usepackage[left=2cm, right=2cm, top=2cm]{geometry}
\usepackage[utf8]{inputenc}
\newtheorem{lemma}{Lemme}[section]
\newtheorem{theorem}{Théorème}
\newtheorem{definition}{Définition}
\setlength{\parskip}{0.22cm}
\usepackage{xcolor}

\definecolor{codegreen}{rgb}{0,0.6,0}
\definecolor{codegray}{rgb}{0.5,0.5,0.5}
\definecolor{codepurple}{rgb}{0.58,0,0.82}
\definecolor{backcolour}{rgb}{0.95,0.95,0.92}

\lstdefinestyle{mystyle}{
    backgroundcolor=\color{backcolour},   
    commentstyle=\color{codegreen},
    keywordstyle=\color{magenta},
    numberstyle=\tiny\color{codegray},
    stringstyle=\color{codepurple},
    basicstyle=\ttfamily\footnotesize,
    breakatwhitespace=false,         
    breaklines=true,                 
    captionpos=b,                    
    keepspaces=true,                 
    numbers=left,                    
    numbersep=5pt,  
    showspaces=false,                
    showstringspaces=false,
    showtabs=false,                  
    tabsize=2
}

\lstset{style=mystyle}
\usepackage{biblatex}
\addbibresource{rapport.bib}

\title{Rapport de stage : Vérification et preuve formelle dans le modèle Heard-Of}
\date{mars 2020 - août 2020}
\author{Louis Penet de Monterno - stage encadré par Bernadette Charron-Bost}

\begin{document}

\maketitle
\tableofcontents
\newpage

\section{Introduction}

\subsection{Contexte}

On se place dans le contexte d'un réseau de machines, et on souhaite que ce réseau exécute une certaine tâche, malgré les pannes pouvant survenir.
Une abondante littérature propose différentes approches permettant de modéliser les systèmes distribués, ainsi que les différents types de pannes possibles.
On envisage généralement le réseau comme un ensemble de processus, qui sont des machines à états. Ces machines peuvent communiquer en s'envoyant des messages.
On fait la distinction entre systèmes synchrones et asynchrones :
Dans un système asynchrones, les processus progressent à des rythmes totalement arbitraires \cite{flp} \cite{ben_or}, tandis que dans les système synchrones, 
il progressent selon un rythme commun à l'ensemble du système.
Les relations entre ces deux types de systèmes ont été explorés dans \cite{partial_sync} \cite{gafni}.
La façon de modéliser les pannes est très diverse : crash ou retard de processus, messages perdus ou altérés, messages livrés dans le désordre ...

Ce travail se place dans le cadre du "modèle Heard-Of" \cite{model_ho}.
Ce modèle est synchrones, les processus progressent par une succession de rounds "clos par communication" \cite{closed_communic} .
C'est-à-dire qu'au sein d'un même round, les processus peuvent communiquer.
On localise les pannes au niveau des liaisons entre processus. Ainsi, pour un round donné, un processus peut, ou non, envoyer un message à un autre processus.
L'avantage de ce modèle est sa grande flexibilité : différentes hypothèses régissant les possibilités de communication entre processus peuvent être envisagées.
La diversité de ces hypothèses sur la connectivité du réseau permet de modéliser un grand nombre de situations.
Les pannes byzantines peuvent aussi être intégrées au modèle, mais ne feront pas l'objet de ce document.

\subsection{Problème à traiter}

Cet article s'intéresse tout particulièrement au problème du consensus : les processus ont chacun une valeur initiale, et doivent s'accorder sur une valeur parmi l'ensemble des valeurs initiales.
Des travaux antérieurs étudient en profondeur les possibilités offertes par un système modélisé de cette manière, en fonction des hypothèses faites sur la connectivité du réseau.
Ainsi, des algorithmes tels que "Uniforme Voting" sont capables, sous certaines hypothèses, de résoudre le problème du consensus.
Mais les travaux existants font une hypothèse qui limite considérablement leur portée, en supposant les départs synchrones : les processus démarrent tous au même moment, au sein d'un même premier round.
Cela peut s'avérer très contraignant, par exemple dans le cas où le système doit effectuer une série de tâches, dont le temps d'exécution n'est pas prévisible.
Dans une telle situation, un retard dans un processus va poser problème dès qu'il faudra passer à la tâche suivante.

Une première solution à ce problème consisterait à resynchroniser le système quand cela est nécessaire. Cela fait l'objet de l'article sur l'algorithme du "firing-squad" \cite{firing_squad}.
Cet algorithme peut être démarré par les processus, sans contrainte sur la synchronisation des départs. Mais, à un certain round, tous les processus "font feu" en même temps, et
peuvent donc commencer l'exécution d'une autre tâche de manière synchrone.
Malheureusement, cet article montre qu'un tel algorithme ne peut fonctionner qu'avec des hypothèses très fortes sur la connectivité du réseau.
Ces hypothèses sont difficilement conciliables avec la plus élémentaire tolérance aux pannes, qui est l'un des principaux but de l'algorithmique distribuée.

Donc, plutôt que de resynchroniser le système, il s'agirait de trouver des algorithmes qui tolèrent les départs asynchrones, et sans compromettre la tolérance aux pannes.
Cette solution permettrait au systèmes de maintenir une meilleure parallélisation des tâches qu'une solution basée sur le "firing-squad".
En effet, contrairement à l'algorithme du "firing-squad", il ne serait pas nécessaire d'attendre à chaque fois le processus le plus lent du réseau.
Tout cela fait l'objet de ce travail de recherche.

\subsection{Contribution proposée}

Une première contribution consista à montrer que l'algorithme "One-Third rule" permet de donner un premier algorithme de consensus capable de tolérer les départs asynchrones.

Ensuite, en cherchant à adapter d'autres algorithmes de consensus connus,
pour les rendre compatibles avec départs asynchrones, un problème intermédiaire, appelé "problème de synchronisation modulo $k$", a été identifié.
En effet, de nombreux algorithmes de consensus, tels que "Uniforme Voting" \cite{model_ho} ou Paxos \cite{paxos},
reposent sur une alternance de phases, que les processus sont supposés exécuter de façon synchronisée.
Si un algorithme contient $k$ phases, il est nécessaire que les processus démarrent au cours de rounds qui soient congrus modulo $k$.
Cet article propose donc un algorithme qui, en s'inspirant de \cite{firing_squad},
résout le problème de synchronisation modulo $k$, et ouvre donc la voie à la résolution du consensus avec les départs asynchrones.

\subsection{Preuves proposées}

L'un des avantages du modèle Heard-Of, par rapport aux approches concurrentes, est d'être facilement exprimable formellement, ce qui le rend particulièrement propice à l'écriture de preuves formelles.
Afin de renforcer la solidité des preuves d'algorithmes, cet article est accompagné des preuves, qui ont été vérifiées par l'assistant de preuve Isabelle.
Dans la dernière section de ce document, à défaut d'inclure l'ensemble du code Isabelle, je présenterai les quelques définitions essentielles du modèle Heard-Of et des algorithmes, ainsi que
les énoncés des théorèmes qui auront été prouvés.

\section{Description du modèle}

\subsection{Présentation générale}

Dans le modèle Heard-Of, les processus sont décrits par des machines à états (voir définition formelle ci-dessous).
Le système est synchrone, c'est-à-dire que la progression du système est subdivisée en rounds. À chaque round, chaque processus :
\begin{itemize}
	\item envoie aux autres un message, en fonction de l'état dans lequel il se trouve,
	\item reçoit une partie des messages qui lui sont adressés par ses pairs \emph{au cours de ce même round},
	\item modifie son état, en fonction des messages reçus, et de son état antérieur.
\end{itemize}

Pour une exécution donnée (voir définition formelle ci-dessous), la connectivité du réseau peut être décrite par une suite de graphes $(\mathds{G}_r)_{r \in \mathds{N}}$, appelée \textit{graphe dynamique} :
au round $r$, le processus $p$ est capable d'envoyer au processus $q$ si et seulement si le graphe $\mathds{G}_r$ contient l'arête $(p,q)$.

On ne peut résoudre aucun problème intéressant dans un tel système si on suppose que la connectivité est arbitrairement mauvaise. Dans le cas extrême, le graphe dynamique est une suite de graphes vides, 
donc aucune connexion ne fonctionne jamais.
On est donc amené à restreindre l'ensemble des graphes dynamiques possibles. Ces restrictions prennent généralement la forme de \emph{prédicats de communications}.

%Dans la litérature, on rencontre plusieurs façons de modéliser les pannes, par exemple l'article \cite{dds} envisage entre autre :

	%\item Les "crash-failure", c'est-à-dire les cas où des processus peuvent inopinément cesser de fonctionner.
	%\item Les échanges de messages, c'est-à-dire la réception des messages dans un ordre chronologiquement différent de l'envoi.


Par exemple, pour modéliser un système sans aucune panne, il suffit de considérer le prédicat $\mathcal{P}_{complet}$, dans lequel tous les messages sont toujours livrés :

$$\mathcal{P}_{complet} \equiv \forall r \in \mathds{N}, \forall p \in \Pi, HO(p, r) = \Pi$$

Ici, $HO(p, r)$ désigne l'ensemble des voisins entrants de $p$ dans le graphe $\mathds{G}_r$, et $\Pi$ désigne l'ensemble des nœuds du réseau.
Ce prédicat exprime le fait que, à chaque round, le graphe dynamique est complet.

Certains articles modélisent les pannes par des \emph{crash-failures} \cite{dds}.
Pour modéliser un système avec $k$ crash-failures dans le modèle Heard-Of,
il suffit d'exprimer le fait qu'il existe à chaque round $r$ un quorum $S_r$ d'au moins $|\Pi| - k$ processus dont les messages sont toujours livrés,
Les processus ayant échoué ne sont plus jamais entendus.

$$\mathcal{P}_{k-crash} \equiv \exists (S_i)_{i \in \mathds{N}}, \forall r \in \mathds{N}, S_{r+1} \subseteq S_r \wedge |S_r| \geq |\Pi| - k \wedge (\forall p \in \Pi, HO(p, r) = S_r)$$

L'objectif de cet article est d'établir des algorithmes de consensus ayant une très bonne résistance aux pannes. Pour cela, on s'intéressera particulièrement au prédicat suivant :

$$\mathcal{P}_{\xi-nek} \equiv \exists \xi \in \Pi, \forall r \in \mathds{N}, \forall p \in \Pi, \xi \in HO(p,r)$$

Lorsqu'un graphe dynamique vérifie ce prédicat, chacun des graphes contiennent une "étoile" dont le centre est $\xi$.
Ce prédicat est au moins aussi fort que l'hypothèse $|\Pi| - 1$ crash-failures :
il exprime le fait qu'il existe au moins un processus fiable dans le réseau, qui parvient toujours à faire parvenir ses propres messages.
Ce processus, noté $\xi$ n'a pas besoin d'être connu par les autres processus du réseau.
Les processus autres que $\xi$ peuvent communiquer de manière totalement arbitraire.

Cette hypothèse sur le réseau est en fait très faible : un réseau avec aucun processus fiable serait un réseau de très mauvaise qualité. Cependant, on envisagera quand même des versions
davantage affaiblies de ce prédicat.

$$\mathcal{P}_{nek} \equiv \forall r \in \mathds{N}, \exists \xi \in \Pi, \forall p \in \Pi, \xi \in HO(p,r)$$

Celle-ci tolère le fait qu'à chaque round, le processus supposé fiable peut être différent.

Pour augmenter la résistances aux échecs de communication, on introduit également les prédicats $\mathcal{P}_{T-rooted}$ et $\mathcal{P}_{rooted}$.
Ces prédicats expriment le fait qu'à chaque round, le graphe de communication contient un arbre couvrant tout le système.
Cet arbre est supposé fixe dans le cas de $\mathcal{P}_{T-rooted}$ (on le note $T$), mais peut varier au fil des rounds dans le cas de $\mathcal{P}_{rooted}$.
Ainsi, $\mathcal{P}_{\xi-nek}$ (respectivement $\mathcal{P}_{nek}$) est un cas particulier de $\mathcal{P}_{T-rooted}$ (respectivement $\mathcal{P}_{rooted}$) où $T$ est de profondeur 1.

\subsection{Départs synchrones - départs asynchrones}

L'objectif de cet article n'est pas d'étudier les systèmes ouverts, où des processus peuvent se joindre au réseau à tout moment.
On suppose donc qu'au round 0, tous les processus sont matériellement actifs. En revanche, il se pourrait qu'au round 0, tous les processus ne soient pas prêt à commencer l'algorithme.
Par exemple, dans le cas d'un algorithme de consensus, les processus commencent chacun avec une valeur initiale. Admettons que cette valeur initiale soit le résultat d'un calcul antérieur.
Dans ce cas, chaque processus ne connaîtra sa propre valeur initiale qu'à partir du round $s^0_p$ auquel ce calcul antérieur aura terminé.
Tant que le processus n'est pas prêt à exécuter un certain algorithme, il se contente de rester passif vis à vis de cet algorithme,
et signale son attente envoyant un message noté $nil$ à tous les processus.
On appelle calendrier d'activation la suite croissante $(\mathcal{A}_r)_{r \in \mathds{N}}$. Au round $r$, $\mathcal{A}_r \subseteq \Pi$ est le sous-ensemble des processus actifs au round $r$.

En fonction de la nature des calculs antérieurs à exécuter, différentes hypothèses peuvent être faites sur le calendrier d'activation.
Ces hypothèses sont également exprimables sous forme de prédicats de communication.
Dans le cadre de ce document, on considèrera en particulier le prédicat suivant :

$$\mathcal{P}_{non-inf} \equiv \exists r \in \mathds{N}, \mathcal{A}_r = \Pi$$

Ce prédicat signifie qu'à partir d'un certain rang $r$, tous les processus sont actifs.

\subsection{Définition d'un algorithme}

On se donne un ensemble non vide $\Pi$ de cardinalité $n$ et  un ensemble non vide ${\cal M}$ dont les éléments seront appel\'es des
	messages et un éléments particulier {\em nil} qui n'est pas dans $\mathcal{M}$.
A chaque  $p \in \Pi$,  on associe  un {\em processus} consistant en la donnée des éléments suivants :
	\begin{itemize}
	\item un ensemble non vide $States_p$ et un  \'el\'ement $sleep_p \notin States_p$ ;
	\item un sous-ensemble   $Init_p \subseteq States_p$ ;
	\item une fonction $S_p : States_p \times \Pi \rightarrow \mathcal{M}$ ;
	\item une fonction 
		$T_p : States_p \times X_\Pi^\mathcal{M}
	  \rightarrow States_p$,
	  où  $X_\Pi^\mathcal{M}$ est le type d'une fonction partielle
			de type $\Pi \rightarrow \mathcal{M}$, pouvant prendre la valeur supplémentaire notée $nil \notin \mathcal{M}$.
	\end{itemize}
Les éléments de 	$States_p$  sont appel\'es \emph{\'etats} de $p$, ceux de $Init_p$ \emph{\'etats initiaux} de $p$,
	la fonction $S_p$ est appel\'ee \emph{fonction d'émission de} $p$ et la fonction $T_p$ \emph{fonction de transition de} $p$.

\begin{definition}\label{def:algo}
Un algorithme  sur $\Pi$ est la donn\'ee d'un processus $(States_p, Init_p, S_p,T_p)$ pour chaque  \'el\'ement $p \in \Pi$.
\end{definition}
\noindent Dans toute la suite, on confondra et notera de la m\^eme mani\`ere $p$ et le processus qui lui est associ\'e.

\subsection{Définition générique d'une exécution}

Dans le mod\`ele Heard-Of, le calcul \'evolue en \emph{round} : dans chaque round $r$, 
	le processus $p$, s'il est actif,  
	\begin{enumerate}
	\item \'emet, \`a destination de chaque processus, un message qui est d\'etermin\'e par sa fonction d'\'emission~$S_p$  
		appliqu\'ee \`a son \'etat courant ;
	\item re\c{c}oit un message, \'emis au round $r$, d'un sous-ensemble de processus $HO(p,r)$ de $\Pi$ ;
        \item  applique la fonction  $T_p$ \`a son \'etat courant  et au vecteur (partiel) form\'e par les messages re\c{c}us (dont le support est 
         $HO(p,r)$).
	\end{enumerate}
Si le processus $p$ est passif au round~$r$ alors il \'emet le message $nil$ et reste dans l'\'etat $sleep_p$.
Un processus ne peut devenir actif qu'au d\'ebut d'un round, auquel cas son \'etat passe de $sleep_p$ \`a 
	un \'etat de $Init_p$.
La donn\'ee de l'ensemble $HO(p,r)$ pour chaque processus $p \in \Pi$ est \'equivalente \`a celle du graphe dirig\'e
	$\mathds{G}_r = (\Pi, E_r)$ dont l'ensemble des n\oe uds est $\Pi$ et dont l'ensemble $E_r$ des arcs dirig\'es 
	est d\'efini par
	$$ (q,p) \in E_r \Leftrightarrow q \in HO(p,r) .$$	
Le graphe $\mathds{G}_r $ correspond exactement aux communications entre processus au round~$r$.
Nous ne discutons pas ici des raisons de l'absence de communication de $q$ vers $p$ \`a un round et reportons pour cela  le lecteur 
	\`a~\cite{model_ho} dans le cas d'un syst\`eme avec des pannes b\'enignes.

Formellement, une \emph{ex\'ecution} de l'algorithme  $(States_p, Init_p, S_p,T_p)_{p\in \Pi}$ est 
	un triplet $\big( \mathds{G} ,  \mathcal{A} , (\sigma^0_p)_{p \in \Pi} \big)$ où :
	\begin{itemize}
		\item $\mathds{G}$ est un \emph{graphe dynamique} sur $\Pi$, i.e., une suite infinie de graphes dirig\'es 
			$\mathds{G}_r = (\Pi, E_r)$ dont l'ensemble des n\oe uds est $\Pi$, 
			de plus, $\mathds{G}_r$ doit toujours contenir les auto-boucles (car un processus peut toujours communiquer avec lui-même) ; 
		\item le \emph{calendrier des activations} $\mathcal{A} = (\mathcal{A}_r)_{r \in \mathds{N}}$ est une suite 
			croissante de sous-ensembles de $\Pi$ 
			avec $\mathcal{A}_0 = \emptyset$ ;
		\item pour chaque processus $p\in \Pi$, $\sigma^0_p \in Init_p$.
	\end{itemize}
Ici,  $\mathcal{A}_r \subseteq \Pi$ modélise le sous-ensemble des processus actifs au round~$r$.
La suite est croissante car, l'état actif est stable : une fois r\'eveill\'e, un processus reste actif pour toujours.

\textbf{Remarques :}
\begin{itemize}
	\item Les départs sont synchrones lorsque tous les processus deviennent actifs au même round, i.e.,
	$$ \forall r \in \mathds{N}, \mathcal{A}_r \in \{\emptyset, \Pi\}  . $$
	\item La donn\'ee de la suite $(\mathcal{A}_r)_{r \in \mathds{N}}$ est  équivalente \`a celle de la fonction 
	$s : \Pi \rightarrow \mathds{N} \cup \{\infty\}$ où 
	$$ s(p) = \left \{ \begin{array}{l ll}
	                          \infty & \mbox{ si  } p \notin \bigcup\limits_{r \in \mathds{N}}  \mathcal{A}_r &  \mbox { ($p$ reste passif) } \\
	                          r  & \mbox{ si  } p \notin \mathcal{A}_{r-1} \mbox{ et } p \in \mathcal{A}_{r}  & \mbox{ ($p$ devient actif au round $r$)}.
	                          \end{array} \right.$$ 
	\item On note $HO(p,r)$ l'ensemble des processus actifs entendus par le processus p au round n : $HO(p,r) = \{q, (q,p) \in E_r\}$

\end{itemize}

Pour toute  exécution de l'algorithme  $(States_p, Init_p, S_p,T_p)_{p\in \Pi}$, on définit inductivement la collection 
	d'\'etats $ \big( \Gamma_p(r) \big )_{p\in\Pi, r\in \mathds{N}}$ de la fa\c{c}on suivante : 
	\begin{itemize}
		\item $\forall r \in \mathds{N},\forall p \in \Pi \setminus \mathcal{A}_{r+1}, \  \Gamma_p(r) = sleep_p$ ;
		\item $\forall r  \in \mathds{N},\forall p \in \mathcal{A}_{r+1} \setminus \mathcal{A}_r, \ \Gamma_p(r) = \sigma^0_p$ ;
		\item $\forall r  \in \mathds{N},\forall p \in \mathcal{A}_{r} , \  \Gamma_p(r+1) = T_p (\Gamma_p(r) ,M_p^{r+1})$
			où $M_p^r$ est la fonction partielle de type $X_\Pi^\mathcal{M}$ définie par 
			$$ M_p^r(q) = \left \{ \begin{array}{l l}
	                         nil  & \mbox{ si  } q \in (\Pi \setminus \mathcal{A}_r  ) \cap  HO(p,r)  \\
	                         S_q (\Gamma_q(r-1), p)  & \mbox{ si  }   q \in \mathcal{A}_r  \cap  HO(p,r) \\
	                         \mbox{ non d\'efini  } & \mbox{ si  }   q \notin  HO(p,r) .
	                          \end{array} \right.$$ 
	\end{itemize}
Dorénavant, $M_p^r$ est appelée \emph{fonction de réception de $p$ au round $r$}.

\subsection{Problème du Consensus}

	Soit un ensemble de valeurs $\mathcal{V}$ non vide.
	On considère un algorithme $A$ dans lequel les processus reçoivent, lors de leur activation, une valeur initiale $v_p \in \mathcal{V}$,
	et qui prennent, à un round donné, une valeur de décision, également dans $\mathcal{V}$.
	On décrit la valeur initiale des processus à l'aide de la fonction $Val : \bigcup\limits_{p \in \Pi} Init_p  \rightarrow \mathcal{V}$.
	Ainsi, pour une exécution donnée, $v_p = Val(\sigma_p^0)$
	On décrit la valeur de décision des processus à l'aide d'une fonction
	$Dec : \bigcup\limits_{p \in \Pi} States_p  \rightarrow (\mathcal{V} \uplus \{\bot\})$.
	Ainsi, si $p$ a décidé $v$ au round $r$, on a $Dec(\Gamma_p(r)) = v$. Si $p$ n'a pas encore décidé au round $r$, on a $Dec(\Gamma_p(r)) = \bot$.

\begin{definition}
	Une exécution de A \emph{vérifie  l'intégrité} si 
	$$ \forall r \in \mathds{N},\forall p \in \mathcal{A}_{r}, \ Dec(\Gamma_p(r)) \in \{ \bot \} \cup  \{ Val(\sigma^0_q) :  q \in \Pi \}  .$$
\end{definition}

\begin{definition}
	Une exécution de A  \emph{vérifie l'accord} si
	$$\forall r, r'  \in \mathds{N}, \forall p \in \mathcal{A}_{r}, \forall q \in \mathcal{A}_{r'}, 
		\ Dec(\Gamma_p(r)) = \bot \vee Dec(\Gamma_q(r')) = \bot \vee Dec(\Gamma_p(r)) = Dec(\Gamma_q(r')) .$$
\end{definition}

\begin{definition}
	Une exécution de A \emph{vérifie la terminaison} si
	$$ \forall p \in \bigcup\limits_{s \in \mathds{N}} \mathcal{A}_s, \exists r \in \mathds{N}, \ 
		p \in \mathcal{A}_r \wedge Dec(\Gamma_p(r)) \neq \bot .  $$
\end{definition}

On considère deux prédicats $\mathcal{P}_{\mathds{G}}$ et $\mathcal{P}_{cal}$.
Ce premier prédicat définit une famille de graphe dynamique, et le second une famille de calendrier d'activation.
	
\begin{definition}\label{def:resforte}
	Un algorithme \emph{résout le consensus sous $\mathcal{P}_{\mathds{G}}$ et $\mathcal{P}_{cal}$} si toute exécution 
	$( \mathds{G} ,  \mathcal{A} , (\sigma^0_p)_{p \in \Pi})$    de cet algorithme
	avec $ \mathds{G} \models \mathcal{P}_{\mathds{G}}$ et $\mathcal{A}	\models \mathcal{P}_{cal}$  vérifie l'intégrité, l'accord et la terminaison.
\end{definition}


\subsection{Hypothèses de connaissance}

\begin{definition}
	On dit qu'un processus $p$ \textit{connaît} une variable $h$ si la fonction d'émission $S_p$, ou la fonction de transition $T_p$ dépend de $h$. 
\end{definition}

La connaissance qu'ont les processus sur les caractéristiques du système peuvent fortement influer sur la résolubilité de problèmes comme le consensus.
Il est parfois nécessaire que les processus connaissent la taille du réseau $n$ pour que le consensus soit résoluble.
À défaut de connaitre $n$, il est parfois utile que les processus connaissent une borne supérieure $\mathcal{N}$ sur la taille du réseau.

\begin{definition}
	On dit qu'un réseau est \textit{identifié} si les processus connaissent un identifiant $x_p$, unique à chaque processus.
	Un réseau non identifié est dit \textit{anonyme}.
\end{definition}

\section{Algorithme "One-Third Rule"}

Dans cette section, il est question d'un algorithme de consensus relativement simple. Dans cet algorithme, chaque processus partage à chaque round sa propre valeur.
Lorsqu'un processus reçoit une supermajorité de valeurs identiques (c'est-à-dire un quorum constitué de deux tiers des processus du réseau), le processus décide.

Soit $\mathcal{V}$ un ensemble supposé totalement ordonné. Soit $\bot$ un objet vérifiant $\bot \notin \mathcal{V}$.
On définit l'algorithme "One-Third rule" de la façon suivante.
\begin{itemize}
	\item Pour tout processus $p$, on pose $States_p = \mathcal{V} \times (\mathcal{V} \cup \{ \bot \})$.
	Comme $States_p$ est un produit cartésien, on peut définir les notations suivantes :
	\begin{itemize}

		\item $x : \mathcal{V} \times (\mathcal{V} \cup \{ \bot \}) \rightarrow \mathcal{V}$ est la première projection.
			La fonction $Val$ associée à l'algorithme "One-Third rule" est définie par cette fonction $x$.
		\item $dec : \mathcal{V} \times (\mathcal{V} \cup \{ \bot \}) \rightarrow \mathcal{V} \cup \{\bot\}$ est la seconde projection.
			La fonction $Dec$ associée à l'algorithme "One-Third rule" est définie par cette fonction $dec$.

	\end{itemize}
\item Pour tout processus $p$, on pose $Init_p = \mathcal{V} \times \{ \bot \}$. Cet ensemble correspond à l'ensemble des états pour lesquels aucune décision n'a encore été prise.
\item Les fonctions de transition et d'émission sont définies par les pseudo-code ci-dessous.
\end{itemize}
Pour toute fonction de réception $M$ de type $X_\Pi^\mathcal{V}$, on note $\widetilde{M}$ la fonction de type $\mathcal{V} \rightarrow \mathds{N}$ définie par $\widetilde{M}(v) = |M^{-1}(v)|$.
Ainsi $\widetilde{M}(v)$ est le nombre d'occurrence du message $v$ parmi le multi-ensemble de messages reçus.
On note également $min \{\widetilde{M}^{-1} (max \widetilde{M})\}$  le minimum parmi les messages les plus fréquents. Cette expression est nécessairement une valeur de $\mathcal{V}$.
On note enfin $Sup(M)$ le support de $M$ (ie. $Sup(M) = \{p \in \Pi, M(p) \in \mathcal{V}\}$). 

\begin{algorithm}[htb]
\begin{distribalgo}[1]
\BLANK \INDENT{\textbf{Initialisation:}}
  \STATE $x_p :=\, v_p$ \COMMENT{  $v_p$ est la valeur initiale de $p$ }
  \STATE $dec_p :=\, \bot$ 
%  \STATE $vote_p \in V\cup\{ ? \}$, initially $?$

\ENDINDENT \BLANK

\INDENT{\textbf{Round $r$:}}
 \INDENT{$S_p:$}
    \STATE envoyer $\langle\, x_p\, \rangle$ à tous les processus
  \ENDINDENT
  \BLANK
	\INDENT{$T_p(M):$}
	\IF{$|Sup(M)| > 2 n/3 $}
	  \STATE $x_p := min \{\widetilde{M}^{-1} (max \widetilde{M})\}$ \COMMENT{la valeur minimale parmi les $x$ les plus fréquents reçus des processus actifs}
		\IF{$\widetilde{M}(x_p) > 2 n/3$} 
		  \STATE $dec_p := x_p$ \COMMENT{plus de $2 n/3$ des valeurs reçues valent $x_p$}
        \ENDIF
      \ENDIF
  \ENDINDENT
\ENDINDENT \BLANK


\caption{L'algorithme {\em One-Third rule}} \label{algo:R}
\end{distribalgo}

\end{algorithm}

On introduit tout d'abord la notion de graphe dirigé $G=(V,E)$ \emph{$S$-uniforme}, où $S\subseteq V$ est un ensemble de nœuds de $G$ :
	$$ \forall q \in S, \  \{ p \in V : (p,q) \in E\} = S .$$
Autrement dit, l'ensemble des voisins entrants d'un nœud de $S$ est $S$.

Le graphe $G$ est dit $p$-\emph{superconnecté} si 
	$$ | \{ q \in V : (q ,p ) \in E\} | > 2 |V|/3 .$$

On prouve alors la terminaison pour toute exécution de l'algorithme dont le graphe dynamique $ \mathds{G} $ vérifie  les prédicats suivants :
\begin{itemize}
	\item $P_{S-unif-\infty} \equiv
		\forall r \in \mathds{N}, \exists t \in \mathds{N}, \exists S_t \subseteq \Pi, t > r  \wedge |S_t | > \frac{2 n}{3} \wedge  \mathds{G}_t \mbox{ est $S_t $-uniforme} .$
	 \item $P_{supermaj-\infty} \equiv
		\forall r \in \mathds{N}, \forall p\in\Pi, \exists t \in \mathds{N}, t > r  \wedge \mathds{G}_t \mbox{ est $p$-superconnecté} .$
\end{itemize}

\begin{theorem}
	L'algorithme "One-Third rule" résout  le consensus lorsque les processus connaissent la taille du réseau,
	et lorsque les prédicats $P_{S-unif-\infty}$ et $P_{supermaj-\infty}$ sont vérifiés.
\end{theorem}

La preuve de ce résultat est reportée en annexe.

\textbf{Remarque :} Le théorème précédent est très proche du théorème 8 démontré dans \cite{model_ho}.
Cependant, \cite{model_ho} utilise un prédicats de communication qui pose problème :

$$P_{unif} \equiv \exists \Pi_0, |\Pi_0| > 2n/3 \wedge \forall p \in \Pi, HO(p, r) = \Pi_0$$

On montre aisément que ce prédicat est difficilement conciliable avec l'hypothèse faite concernant les auto-boucles.
La notion de S-uniformité permet de corriger cette imperfection.

\section{Théorèmes de résolubilité}

L'algorithme "One-Third rule" permet de résoudre le consensus, mais nécessite cependant que les processus connaissent la taille du réseau.
L'objectif de cette section est de découvrir un algorithme qui évite cette contrainte.
On aimerait trouver un algorithme qui fonctionne sous les prédicats $\mathcal{P}_{\xi-nek}$ et $\mathcal{P}_{non-inf}$.
D'abord, on montre que des versions affaiblies de ces prédicats rendent impossible la résolution du consensus.

\subsection{Théorèmes d'impossibilité}

Ce premier théorème montre que le prédicat $\mathcal{P}_{non-inf}$ est indispensable pour la résolution du consensus dans un graphe avec étoile recouvrante.

\begin{theorem}
	Il n'existe pas d'algorithme qui résolve le consensus sous le prédicat $\mathcal{P}_{\xi-nek}$, même si les processus connaissent la taille du réseau.
\end{theorem}
\begin{proof}
	On suppose qu'un tel algorithme existe, et on construit une exécution qui viole l'accord.

	\begin{description}
		\item[Exécution 0 : ] Le graphe dynamique est une étoile constante, centrée sur $\xi$. $\xi$ est passif pour toujours. Les autres processus ont 0 comme valeur initiale.
			Et ils s'activent en temps fini. La terminaison assure qu'il décident tous 0 en temps fini.

		\item[Exécution 1 : ] Le graphe dynamique est une étoile constante, centrée sur $\xi$. $\xi$ est passif pour toujours. Les autres processus ont 1 comme valeur initiale.
			Et ils s'activent en temps fini. La terminaison assure qu'il décident tous 1 en temps fini.

		\item[Exécution 2 : ] Le graphe dynamique est une étoile constante, centrée sur $\xi$. $\xi$ est passif pour toujours. Les autres processus ont différentes valeurs initiales.
			En particulier, un processus $p_0$ a 0 comme valeur initiale, et $p_1$ a 1.
			Et ils s'activent en temps fini. Pour $p_0$, ce scénario est indistinguable du scénario 0, donc $p_0$ décide 0.
			Pour $p_1$, ce scénario est indistinguable du scénario 1, donc $p_1$ décide 1.  Cela viole l'accord.
	\end{description}
\end{proof}

Ce deuxième théorème montre que la racine de l'étoile recouvrante doit être fixe pour que le consensus soit résoluble.

\begin{theorem}
	Il n'existe pas d'algorithme qui résolve le consensus sous les prédicats $\mathcal{P}_{nek}$ et $\mathcal{P}_{non-inf}$, même si les processus connaissent la taille du réseau.
\end{theorem}
\begin{proof}
	On suppose qu'un tel algorithme existe, et on construit une exécution qui viole l'accord.
	Soient $p_1, p_2 \in \Pi$.
	\begin{description}

		\item[Exécution 1 :] $\mathds{G}_r$ est pour tout $r$ égal à l'étoile centrée en $p_1$. $p_1$ s'active en temps fini, donc la terminaison assure que $p_1$ décidera en un round $t$.
		\item[Exécution 2 :] Pour tout $r \leq t$, $\mathds{G}_r$ est l'étoile centrée en $p_1$. $p_1$ s'active au même round que dans l'exécution précédente.
			Pour tout $r > t$, $\mathds{G}_r$ est l'étoile centrée en $p_2$. On suppose que $p_2$ s'active au round $t+1$.
			Dans ces conditions, $p_2$ ne reçoit jamais de message. La terminaison et l'intégrité assurent que $p_2$ décide finalement sa valeur initiale,
			tandis que $p_1$ a déjà décidé. Dans ces conditions, l'accord est impossible à assurer.

	\end{description}
\end{proof}

Il est possible qu'un graphe dynamique $\mathds{G}$ ne respecte pas le prédicat $\mathcal{P}_{\xi-nek}$, mais qu'en "agrégeant" plusieurs rounds, on obtienne un graphe dynamique mieux connecté,
et qui vérifie $\mathcal{P}_{\xi-nek}$.
Cependant, on montre que si les processus ne connaissent pas le nombre de rounds à agréger, le consensus n'est pas résoluble.

\begin{definition}
	Étant donné un graphe dynamique $\mathds{G} = (V, E_i)_{i \in \mathds{N}}$.
	Étant donné deux entiers $t_1$ et $t_2$, on construit le graphe $\mathds{G}(t_1 : t_2) = (V, E_{agreg})$ de la manière suivante :

	$$\forall p \in V, \forall q \in V, (p, q) \in E_{agreg} \equiv \exists h : \mathds{N} \rightarrow \Pi, \forall i \in \{t_1, t_1 + 1, ..., t_2\}, (h(i), h(i+1)) \in E_i$$
\end{definition}

\begin{definition}
	Étant donné un prédicat $\Phi$ s'appliquant sur un graphe.
	On définit le prédicat $P_{borné}(\Phi)$ sur un graphe dynamique
	$\mathds{G}$ par $$P_{borné}(\Phi) \equiv \exists b \in \mathds{N}, \forall t \in \mathds{N}, \mathds{G}(t:t+b) \models \Phi$$
\end{definition}

\begin{theorem}
	Il n'existe pas d'algorithme qui résolve le consensus sous les prédicats $P_{borné}(\Phi_{\xi-nek})$ et $\mathcal{P}_{non-inf}$, même si les processus connaissent la taille du réseau.
\end{theorem}
\begin{proof}
	On suppose qu'un tel algorithme existe, et on construit une exécution qui viole l'accord.
	Soient $p_1, p_2 \in \Pi$.
	\begin{description}

		\item[Exécution 1 :] $\mathds{G}_n$ est pour tout $n$ égal à l'étoile centrée en $p_1$. On exécute l'algorithme $A$.
			$p_1$ s'active en temps fini, donc la terminaison assure que $p_1$ décidera en un round $r_1$.
		\item[Exécution 2 :] $\mathds{G}_n$ est pour tout $n$ égal à l'étoile centrée en $p_2$. On exécute l'algorithme $A$.
			$p_2$ s'active en temps fini, donc la terminaison assure que $p_2$ décidera en un round $r_2$.
		\item[Exécution 3 :] Pour tout $n \leq r_0 + r_1$, $\mathds{G}_n$ est le graphe sans aucune arête. Pour tout $n > r_0 + r_1$, $\mathds{G}_n$ est l'étoile centrée en $p_1$.
			$p_1$ et $p_2$ s'activent au même round que lors des deux précédentes exécutions.
			Pour $p_1$, ce scénario est indistinguable du scénario 1, donc $p_1$ décidera au round $r_1$.
			Pour $p_2$, ce scénario est indistinguable du scénario 1, au moins jusqu'au round $r_2$. Donc $p_2$ décidera au round $r_2$.
			Dans ces conditions, l'accord est impossible à assurer.

	\end{description}
\end{proof}

\subsection{Algorithme "Uniforme Voting"}

Il reste maintenant à traiter le cas où les prédicats $\mathcal{P}_{\xi-nek}$ et $\mathcal{P}_{non-inf}$ sont vérifiés.
Ci-dessous se trouve l'algorithme "Uniforme Voting", tiré de \cite{model_ho}.
Cet algorithme est constitué de deux phases qui alternent en fonction de la parité du round :
\begin{itemize}
	\item Une phase durant laquelle les processus échangent leur valeur (lignes 21-23).
	\item Une phase durant laquelle les processus votent pour leur valeur, et décident en cas d'unanimité (lignes 13-19).
\end{itemize}

Bien qu'initialement conçu pour fonctionner lorsque les départs sont synchrones, on peut aisément adapter cet algorithme pour tolérer les départs asynchrones.
Il s'agit simplement de préciser comment prendre en charge les $nil$ envoyés par les processus passifs.

Cependant, cette simple transposition ne suffit pas à rendre l'algorithme tolérant aux départs asynchrones. Le problème est le suivant :
Si un processus s'active à un round pair, sa phase d'échange de valeur aura lieu à chaque round impair, et sa phase d'échange de vote à chaque round pair.
À l'inverse,
si un processus s'active à un round impair, sa phase d'échange de valeur aura lieu à chaque round pair, et sa phase d'échange de vote à chaque round impair.
Donc si les processus du réseau démarrent à des rounds ayant différentes parité, on aura, au sein d'un même round,
des processus qui feront leur phase d'échange de valeur, et d'autre leur phase d'échange de vote.
Dans ces conditions, la sûreté de l'algorithme ne tient plus.

Il s'agit donc de faire en sorte que tous les processus s'activent à des rounds ayant tous la même parité. 
On appelle cela le \emph{problème de synchronisation modulo 2}.
Comme ce problème fera l'objet d'une prochaine section, on va provisoirement supposer ce problème résolu en supposant vrai le prédicat 

$$\mathcal{P}_{sync-mod-2} \equiv \exists c \in \{0, 1\}, \forall k \in \mathds{N}, \mathcal{A}_{2k+c} = \mathcal{A}_{2k+c+1}$$

Voici maintenant l'algorithme "Uniforme Voting	Voting" et sa preuve de correction.

\begin{algorithm}[htb]
\scriptsize{
\begin{distribalgo}[1]
\begin{tabular}{ll}
\begin{minipage}{33em}


\INDENT{\textbf{Initialisation:}}
  \STATE $x_p := v_p$ ~~~~~~~~\{\emph{$v_p$ est la valeur initiale $p$}\}
  \STATE $vote_p \in V\cup\{ ? \}$, initialement $?$
  \STATE $phase_p = true$

\ENDINDENT
\BLANK

\INDENT{\textbf{Round $r$:}}
	\INDENT{$S_p^r:$}
		\IF{$phase_p$}
			\STATE envoyer $\langle x_p , vote_p \rangle$ à tous les processus
		\ELSE
			\STATE envoyer $\langle x_p \rangle$ à tous les processus
			\ENDIF
	\ENDINDENT
	\BLANK
	\INDENT{$T_p^r:$}

		\IF{$phase_p$}
			\IF{$M(q) = \langle v, v \rangle$}
				\STATE $x_p:= v$ ~~~~~~~~\{un vote reçu\}
			\ELSE
				\STATE $x_p :=$ smallest  $w$ from  $\langle w , ? \rangle$ received
			\ENDIF
			\IF{$M(\Pi) = \langle v, v \rangle$}
				\STATE $DECIDE(v)$ ~~~~~~~~\{décider si $p$ ne reçoit que des votes identiques\}
			\ENDIF
			\STATE $vote_p :=\ ?$
		\ELSE
			\STATE $ x_p := min M(\Pi) \setminus \{nil\}$ ~~~~~~~~\{plus petites valeur reçue\}
			\IF{$M(\Pi) = \{v\}$}
				\STATE $vote_p := v$ ~~~~~~~~\{toute les valeurs reçues identiques, aucun nil\}
			\ENDIF
		\ENDIF
		\STATE $phase_p := \neg phase_p$
	\ENDINDENT
\ENDINDENT

\end{minipage}
\end{tabular}

\caption{The {\em UniformVoting} algorithm}
\label{unifvotfig}
\end{distribalgo}
}
\end{algorithm}

\subsubsection{Intégrité}
\begin{lemma}
	Toute exécution de l'algorithme "Uniforme Voting" vérifie l'intégrité lorsque le prédicat $\mathcal{P}_{sync-mod-2}$ est vérifié.
\end{lemma}
\begin{proof}
	Il suffit de montrer par récurrence qu'à chaque round, les valeurs stockées dans les processus actifs appartiennent nécessairement à l'ensemble des valeurs initiales.
\end{proof}

\subsubsection{Accord}

\begin{lemma}
	Toute exécution de l'algorithme "Uniforme Voting" vérifie l'accord lorsque le graphe dynamique vérifie le prédicat $\mathcal{P}_{\xi-nek}$
	et le calendrier d'activation vérifie $\mathcal{P}_{sync-mod-2}$.
\end{lemma}
\begin{proof}
	Si un processus $p$ décide une valeur $v$ au round $r$, nécessairement, le processus $\xi$ au centre de l'étoile a voté $v$ au round $r$.
	Donc, au round $r$, tous les processus actifs adoptent $v$.
	Donc toute valeur décidée ultérieurement sera nécessairement $v$. Pour s'en convaincre, on montre aisément par récurrence sur $k$ la proposition suivante :
	$$\forall k \in \mathds{N}, \forall q \in \mathcal{A}_{r+2k}, vote_p(2k) = v \wedge x_q(r+2k) = v \wedge x_q(r+2k+1) = v$$

	Cela achève l'accord.
\end{proof}

\subsubsection{Terminaison}

	\begin{lemma}
		Étant donné une exécution vérifiant $\mathcal{P}_{\xi-nek}$ et $\mathcal{P}_{sync-mod-2}$.
		Soit $r$ le round auquel $\xi$, le centre de l'étoile, s'active.
		La suite $(x_\xi(r+k))_{k \in \mathds{N}}$, représentant la succession des valeurs de $\xi$, est décroissante.
	\end{lemma}
	\begin{proof}
		Soit $k \in \mathds{N}$. Soit $M$ la fonction de réception de $\xi$ au round $r+k+1$.
		\begin{itemize}

			\item Si $k+1$ est impair, la ligne 21 du pseudo-code assure que $x_\xi(r+k+1) = min(M(\Pi) \setminus \{nil\})$.
				Or $M(\xi) = x_\xi(r+k)$.  Donc $x_\xi(r+k+1) \leq x_\xi(r+k)$.
			\item Si $k+1$ est pair et si $\exists q \in \mathcal{A}_{r+k+1}, M(q) = \langle v, v \rangle$,
				on a nécessairement $v = x_\xi(r+k)$, puisque $\xi$ a envoyé $x_\xi(r+k)$ au round $r+k$ (cf. lignes 20-21).
				Donc $x_\xi(r+k+1) = x_\xi(r+k)$.
			\item Sinon la ligne 11 du pseudo-code assure que $x_\xi(r+k+1) = min(M(\Pi) \setminus \{nil\})$.
				Or $M(\xi) = \langle x_\xi(r+k), * \rangle$.
				Donc $x_\xi(r+k+1) \leq x_\xi(r+k)$.

		\end{itemize}
		Dans tous les cas, $x_\xi(r+k+1) \leq x_\xi(r+k)$.
	\end{proof}
		

	\begin{lemma}
		Toute exécution de "Uniforme Voting" vérifie la terminaison lorsque le graphe de communication vérifie $\mathcal{P}_{\xi-nek}$
		et lorsque le calendrier d'activation vérifie $\mathcal{P}_{non-inf}$ et $\mathcal{P}_{sync-mod-2}$.
	\end{lemma}
	\begin{proof}
		Soit $r_0$ le round auquel tous les processus sont actifs.

		La suite $(x_\xi(r_0+k))_{k \in \mathds{N}}$ est décroissante et ne contient que des valeurs initiales. Donc elle se stabilise sur une valeur $v$ à partir d'un certain round $r_0+k_0$.
		On considère maintenant le round $r_0+2k_0$, qui est un round d'échange de vote.
		$\xi$ envoie $\langle v, * \rangle$ à tous les processus. Les lignes 8 à 11 du pseudo-code assurent que $\forall q \in \mathcal{A}_{r_0+2k_0}, x_q(r_0+2k_0) \leq v$.

		Soit $M$ la fonction de réception de $\xi$ lors du round $r_0+2k_0+1$.
		Comme $x_\xi(r_0+2k_0+1) = v$, la ligne 19 assure que $\xi$ n'a pas reçu de message inférieur à $v$.
		Donc $M(\Pi) = \{v\}$. Donc $vote_\xi(r_0+2k_0+1) = v$. Donc au round $r_0+2k_0+2$, la ligne 9 assure que tous les processus adoptent $v$.

		Au round $r_0+2k_0+3$, les processus ne reçoivent que des messages contenant $v$, donc au round $r_0+2k_0+4$, tous les processus votent $v$, donc tous les processus décident.
	\end{proof}
\subsection{Résultat}

Les trois sections précédentes permettent d'affirmer le théorème suivant :

\begin{theorem}
	L'algorithme "Uniforme Voting" résout le consensus lorsque les prédicats $\mathcal{P}_{sync-mod-2}$, $\mathcal{P}_{\xi-nek}$ et $\mathcal{P}_{non-inf}$ sont vérifiés.
\end{theorem}

\section{Problème de synchronisation modulo $k$}

Le but de cette section est de proposer un algorithme permettant de synchroniser les différentes phases malgré les départs asynchrones.
En plus de l'algorithme "Uniforme Voting", le célèbre algorithme Paxos \cite{paxos} fonctionne également par alternance de phases.

L'algorithme qui sera présenté s'inspire de l'algorithme du "firing-squad" \cite{firing_squad}.
Dans l'algorithme du firing-squad, les processus ont chacun un compteur, qu'ils incrémentent à chaque round. Ils partagent la valeur de leur compteur à tous leurs voisins sortants, 
et s'ils reçoivent plusieurs valeurs en conflit, ils adoptent la valeur minimale.
Si, pour un processus $p$, le compteur dépasse une certaine valeur, $p$ décide alors de \emph{faire feu}.
Si le graphe dynamique est constamment fortement connexe, on peut montrer que tous les processus font feu au même round.

Dans l'algorithme présenté ci-dessous, les compteurs sont dans $\mathds{Z}/k\mathds{Z}$ plutôt que dans $\mathds{N}$.
On montrera que, dans ce cas, les numéros de rounds auxquels les processus font feu sont mutuellement congrus modulo $k$.
Pour des raisons historiques, on considèrera que $\mathds{Z}/k\mathds{Z} = \{1, 2, ... k\}$ plutôt que $\mathds{Z}/k\mathds{Z} = \{0, 1, ... k-1\}$.

\begin{definition}

	Soit un paramètre $k > 1$. Soit $S_{exit} \subseteq States_p$ un sous-ensemble d'états finaux.
	Étant donnée une exécution d'un algorithme $A$, pour tout $p \in \Pi$, on note $t_p$ le round auquel $p$ atteint $S_{exit}$ ($t_p = \infty$ sinon).
	Cette exécution de l'algorithme $A$ est sûre vis à vis du problème de synchronisation modulo $k$ si,
	$$\exists c \in \mathds{N}, \forall p \in \bigcup\limits_{i \in \mathds{N}} \mathcal{A}_i, t_p \neq \infty \Rightarrow t_p~mod~k = c$$

\end{definition}

\begin{definition}

	Une exécution de l'algorithme $A$ vérifie la vivacité vis à vis du problème de synchronisation modulo $k$ si,
	$$\forall p \in \bigcup\limits_{i \in \mathds{N}} \mathcal{A}_i, t_p \neq \infty$$

\end{definition}
\begin{definition}
	L'algorithme $A$ résout le problème de synchronisation modulo $k$, si toute exécution de $A$ est sûre et vivace.
\end{definition}

Pour la suite, on considère une valeur $k > 2$ quelconque.

\subsection{Algorithme}

L'objectif est de résoudre ce problème lorsque les prédicats $\mathcal{P}_{\xi-nek}$ et $\mathcal{P}_{non-inf}$ sont vérifiés.
L'idée de l'algorithme ci-dessous est que chaque processus possède un compteur modulo $k$. À chaque round, il incrémente son compteur, et l'envoie à tous.
Il reçoit alors les valeurs de compteur de tous ses voisins entrants.
La fonction de transition est constituée de quatre branches.
Les processus essayent de se synchroniser avec les autres s'ils s'accordent tous sur une même valeur de compteur (deuxième branche dans la fonction de transition).

Sinon, ils font une tentative de "synchronisation forcée", c'est-à-dire qu'ils essayent de convaincre tous les processus de se synchroniser sur leur propre compteur :
ils adoptent la valeur $k$ (troisième branche). Au prochain round, ils envoient $k$.  Les processus qui reçoivent ce $k$ sont obligés d'adopter 1 (quatrième branche).
Chaque processus ne fait qu'une seule fois cette tentative de synchronisation forcée (la variable $try_p$ sert justement à limiter $p$ à une seule tentative).
On note $t_p$ le round auquel le processus $p$ exécute cette branche, si cela se produit. $t_p = 0$ sinon.

Lorsqu'un processus s'active, il essaye de s'aligner sur les valeurs qu'il entend, avant d'envoyer sa propre valeur.
On introduit donc une valeur $\bot$, qui sera envoyée lors du round d'activation, qui sera traitée comme un $nil$ par les processus récepteurs.

\pagebreak[1]

\begin{algorithm}[htb]
\begin{distribalgo}[1]
\BLANK \INDENT{\textbf{Initialisation:}}
	\STATE $x_p \in \mathds{Z}/k\mathds{Z}$
	\STATE $try_p = true$
	\STATE $fire_p = false$
	\STATE $started_p = false$

\ENDINDENT \BLANK

\INDENT{\textbf{Round $r$:}}
	\INDENT{$S_p:$}
		\IF{$started_p$}
			\STATE envoyer $\langle x_p \rangle$ à tous les processus
		\ELSE
			\STATE envoyer $\bot$ à tous les processus
		\ENDIF
	\ENDINDENT
	\BLANK
	\INDENT{$T_p(M):$}
		\STATE $started_p = true$
		\IF{$M(\Pi) = \{k\}$}
			\STATE $fire_p = true$ ~~~~\COMMENT{si tous les messages reçus valent $k$, aucun $nil$, l'algorithme fait feu}
		\ENDIF
		\IF{$M(\Pi) \setminus \{nil, \bot\} = \{v\}$}
			\STATE $x_p = v+1~mod~k$ ~~~~\COMMENT{si tous les messages ont la même valeur, s'aligner}
		\ELSIF{$try_p \wedge k \notin M(\Pi)$}
			\STATE $try_p = false$ ~~~~\COMMENT{si plusieurs messages sont discordants, faire une tentative de synchronisation forcée}
			\STATE $x_p = k$
		\ELSE
			\STATE $x_p = 1$ ~~~~\COMMENT{si un k a été reçu, toujours s'aligner}
		\ENDIF
	\ENDINDENT
\ENDINDENT 
\caption{L'algorithme {\em SyncMod}} \label{algo:R}
\end{distribalgo}

\end{algorithm}

\subsection{Notations}

Soit $V \subseteq \mathds{Z}/k\mathds{Z}$. On dit que le système est V-valent au round $t$ si $V = \{v \in \mathds{Z}/k\mathds{Z}, \exists p \in \Pi, x_p(t) = v \wedge started_p(t)\}$.
On dit que le système est v-monovalent si le système est $\{v\}$-valent.

On dit que $p$ "fait feu" au round $t$ si $p$ exécute la première branche au round $t$.

\subsection{Preuve}

\begin{lemma}
	Toute exécution de cet algorithme est sûre vis-à-vis du problème de synchronisation modulo k lorsque les prédicats $\mathcal{P}_{\xi-nek}$ et $\mathcal{P}_{non-inf}$ sont vérifiés.
\end{lemma}
\begin{proof}

	On suppose que $p$ fait feu au round $r$, et est le premier. Nécessairement, $\xi \in HO(p,r)$.
	La ligne 12 du code montre que la valeur envoyée par $\xi$ est $k$.
	Donc tous les processus ont reçu un $k$. Soit $p$ un processus actif quelconque. Au round $r$, il exécute, dans sa fonction de transition, l'une des trois dernières branches.
	\begin{itemize}

		\item Il ne peut pas exécuter la troisième branche car $M(\xi) = k$.
		\item S'il exécute la première, deuxième ou la quatrième branche, il adopte 1.

	\end{itemize}

	On montre maintenant par récurrence sur $i$ la proposition suivante :

	$$\forall i \in \mathds{N}, \forall p \in \mathcal{A}_{r+i}, x_p(r+i) = i+1~mod~k$$

	\textbf{Initialisation : } voir ci-dessus

	\textbf{Hérédité :}
	On suppose que $\forall p \in \mathcal{A}_{r+i}, x_p(r+i) = i+1~mod~k$.

	On veut montrer que $\forall p \in \mathcal{A}_{r+i+1}, x_p(r+i+1) = i+2~mod~k$.

	Soit $M$ la fonction de réception de $p$ au round $r+i+1$.
	L'hypothèse de récurrence montre que $M(\Pi) \subseteq \{nil, \bot, i+1~mod~k\}$.
	De plus, $M(\xi) = i+1~mod~k$. Donc $p$ exécute la première ou la deuxième branche de la fonction de transition, et adopte $i+2~mod~k$.
	Cela achève la récurrence.

	La sûreté découle de cette proposition.

\end{proof}

\begin{lemma}
	Si $x_\xi(t) = k$, le système est 1-monovalent au round $t+1$.
\end{lemma}
\begin{proof}
	$\xi$ est le centre de l'étoile.
	Si $x_\xi(t) = k$, au round $t+1$, $\xi$ envoie $k$ à tous les processus. Donc tous les processus, recevant un $k$, exécutent nécessairement la deuxième ou quatrième branche,
	et adoptent donc la valeur 1. Le système devient donc 1-monovalent.
\end{proof}

\begin{lemma}
	Si, au round $s$, $\xi$ est actif, et le système est v-monovalent, pour tout $i \in \mathds{N}$, le système est $v+i~mod~k$-monovalent au round $s+i$.
\end{lemma}
\begin{proof}
	On montre cela par récurrence sur $i$.
	\begin{description}
		\item[Initialisation :] Vrai par hypothèse.
		\item[Hérédité :] On suppose que $\forall p \in \mathcal{A}_{s+i}, x_p(s+i) = v+i~mod~k$.
			On veut montrer que $\forall p \in \mathcal{A}_{s+i+1}, x_p(s+i+1) = v+i+1~mod~k$.
			Au round $s+i+1$, les processus dans $\mathcal{A}_{s+i}$ envoient $v+i~mod~k$, d'après l'hypothèse de récurrence.
			Les processus de $\mathcal{A}_{s+i+1} \setminus \mathcal{A}_{s+i}$ envoient $\bot$. Les autres envoient $nil$.
			Comme $\xi$ est actif, les processus reçoivent tous au moins une fois $v+i~mod~k$. Donc tous les processus actifs exécutent la deuxième branche, et adoptent $v+i+1~mod~k$.
	\end{description}
\end{proof}

\begin{lemma}
	Si $x_\xi(t) = k$, tout processus $p$ fait feu en temps fini.
\end{lemma}
\begin{proof}
	D'après les lemmes 4.2 et 4.3, le système devient 1-monovalent au round $t+1$ et $i~mod~k$-monovalent à tous les rounds $t+i$ suivants.
	À partir du round $s_{max}$, tous les processus sont actifs.
	Ainsi, à un certain round $t+k i$ vérifiant $t+k i \geq s_{max}$, le système est $k$-monovalent, donc au round $t+k i +1$, tous les processus envoient $k$ à leurs voisins sortants.
	Ainsi, les processus ne reçoivent que des $k$, donc tous les processus font feu.
\end{proof}

\begin{lemma}
	Si le système est monovalent au round $t$, tous les processus auront fait feu au plus tard au round $max(t, s_{max})+k$.
\end{lemma}
\begin{proof}
	D'après le lemme 5.3, le système reste monovalent au round $max(t, s_{max})$ et tous les processus sont actifs.
	Donc, au plus après $k$ rounds, le système entrera dans un état $k$-monovalent, et au round suivant, tous les processus enverront $k$.
	Ainsi, tous les processus qui n'auront pas encore fait feu, feront feu.
	Donc, au plus tard au round $max(t, s_{max})+k$, tous les processus auront fait feu.
\end{proof}

On introduit la fonction $C(t) = (x_\xi(t), \{v \in \mathds{Z}/k\mathds{Z}, \exists p \in \Pi, x_p(t) = v\})$.
Ainsi, si $C(t) = (v_0, V)$, le système est V-valent au round $t$.

On introduit un ensemble $\mathcal{F}$ de configurations dites "favorables".
Ainsi, $C(t) = (v, V) \in \mathcal{F} \equiv v = k \vee |V| = 1$.
Les lemmes 5.4 et 5.5 montrent que si une exécution atteint une configuration favorable, la vivacité est garantie.


\begin{lemma}
	Soit $t > max \{t_p, p \in \Pi\} \cup \{s_p, p \in \Pi\}$. Le système est monovalent ou V-valent avec $V = \{1, w\}$ au round $t$.
\end{lemma}
\begin{proof}
	Soit $w_0 = x_\xi(t-1)$. Soit $p \in \mathcal{A}_t$.
	Au round $t$, le processus $p$ reçoit la valeur $w_0$ de la part du processus $\xi$.
	\begin{itemize}
		\item Si $p$ reçoit une valeur autre que $w$ et que $\bot$,
			$p$ n'exécute pas la deuxième branche de la fonction de transition. De plus, $t > t_p$, donc n'exécute pas non plus la troisième branche.
			Donc $p$ exécute la quatrième branche, donc $x_p(t) = 1$.
		\item Sinon, $p$ exécute la deuxième branche de la fonction de transition. Donc $x_p(t) = w = w_0+1~mod~k$.
	\end{itemize}

	Cela prouve le lemme.
\end{proof}

\begin{theorem}
	L'algorithme résout la synchronisation modulo $k$ lorsque les prédicats $\mathcal{P}_{\xi-nek}$ et $\mathcal{P}_{non-inf}$ sont vérifiés.
\end{theorem}
\begin{proof}

	On montre que le système atteint toujours une configuration $C(t) \in \mathcal{F}$.

	\begin{description}
		\item[Cas 1:] Si $t_\xi \neq \infty$, le processus $\xi$ exécute une fois la troisième branche, la vivacité découle du lemme 5.4.
		\item[Cas 2:] Sinon $t_\xi = \infty$, le processus $\xi$ n'exécute jamais la troisième branche.
			Soit $t > max \{t_p \neq \infty, p \in \Pi\} \cup \{s_p, p \in \Pi\}$. Soient $w$ et $V$ tels que $C(t) = (w, V)$.
			\begin{description}
				\item[Sous-cas 2.1:] Si $V = \{w\}$, le système est monovalent, la vivacité découle du lemme 5.5.
				\item[Sous-cas 2.2:] Si $|V| > 1$ et $w > 1$, le lemme 5.6 assure que $V = \{1, w\}$ avec $w \neq 1$.
					\begin{description}
						\item[Sous-sous-cas 2.2.1:] Au round $t+1$, le processus $\xi$ reçoit la valeur 1. Cela est impossible, car on a supposé que $t_\xi = \infty$.
						\item[Sous-sous-cas 2.2.2:] Au round $t+1$, le processus $\xi$ ne reçoit que sa propre valeur. 
							On a donc $C(t+1) = (w+1, \{1, w+1\})$. Au round $t+2$, le sous-cas 2.2 se reproduira.
							On montre donc par récurrence descendante que pour tout $i \in \{k-w, ..., 0\}$,
							on a $C(t+k-i) = (k-i, \{1, k-i\})$. On a donc $C(t+k-w) \in \mathcal{F}$. La vivacité est donc assurée.
					\end{description}
				\item[Sous-cas 2.3:] Si $v = 1$, le lemme 5.5 assure que $V = \{1, w\}$ avec $w \neq 1$.
					Au round $t+1$, le processus $\xi$ reçoit sa propre valeur 1. On a supposé que $t_\xi = \infty$. Donc $\xi$ ne peut pas avoir reçu $w$.
					On a donc $C(t+1) = (2, \{1, 2\})$. On est ramené au cas 2.2.
			\end{description}
		%\item[Sous-sous-cas 2.3.1:] Au round $t+1$, le processus 
	\end{description}

	Les lemmes 5.1, 5.4 et 5.5 permettent donc d'achever la vivacité, ainsi que la sûreté.
\end{proof}

Maintenant que la validité de l'algorithme SyncMod est établie, on peut affirmer le théorème suivant :

\begin{theorem}
	L'algorithme "Uniforme Voting" exécuté en série à la suite de l'algorithme "SyncMod" avec $k = 4$
	résout le consensus lorsque les prédicats $\mathcal{P}_{\xi-nek}$ et $\mathcal{P}_{non-inf}$ sont vérifiés.
\end{theorem}
\begin{proof}
	Le fait d'exécuter l'algorithme "Uniforme Voting" à la suite de SyncMod assure le fait que le calendrier d'activation de "Uniforme Voting" vérifie $\mathcal{P}_{sync-mod-4}$,
	donc à fortiori $\mathcal{P}_{sync-mod-2}$.
	La preuve de validité de "Uniforme Voting", précédemment présentée, s'applique donc.
\end{proof}

\section{Preuves formelles}

Dans la mesure où les preuves proposées dans ce document ont un aspect combinatoire, il y a toujours un risque qu'un cas limite ait été oublié, et invalide une preuve.
Afin de renforcer la solidité de ces preuves, il est possible d'utiliser un assistant de preuve, tel que Coq ou Isabelle.
Le modèle Heard-Of a déjà été traduit en Isabelle \cite{HO_isa},
et cette traduction du modèle Heard-Of a été utilisée pour prouver la correction de plusieurs algorithmes, dont "One-Third rule", "Uniforme Voting".
Cette modélisation était cependant limitée aux exécutions avec départs synchrones.
Il s'agissait donc d'abord d'étendre la modélisation existante du modèle Heard-Of.
En guise d'entraînement, j'ai également écrit la preuve de "One-Third rule" dans le cas des départs asynchrones.
Enfin, j'ai construit la preuve de vivacité de l'algorithme SyncMod.

\subsection{Adaptation du modèle Heard-Of}

On définit d'abord un type pour l'état des processus : soit passif, soit actif, avec un état de type \textit{pst}.

\begin{lstlisting}
datatype 'pst procState = Active "'pst" | Aslept
\end{lstlisting}

On définit le type des messages reçus par les processus : soit le message contient une valeur de type \textit{msg}, soit le processus émetteur est passif,
dans ce cas le processus récepteur reçoit $nil$, soit aucun message n'est reçu, cela se traduit par un message de type $Void$.

\begin{lstlisting}
datatype 'msg message = Content "'msg" | Nil | Void
\end{lstlisting}

On définit ensuite un algorithme comme un tuple composé d'un ensemble d'états initiaux, d'une fonction d'émission et de transition.
La modélisation est faite pour prendre en charge les algorithmes avec coordinateur. Cette possibilité n'a pas été utilisée lors de ce travail de recherche.
Le quatrième argument de la fonction de transition, ainsi que le deuxième argument de la fonction d'émission correspondent au coordinateur du processus considéré.
Le premier argument de la fonction de transition correspond au processus qui change d'état, les deuxième et cinquième arguments correspondent respectivement à l'ancien et au nouvel état du processus.
Le troisième argument correspond à la fonction de réception.

\begin{lstlisting}[mathescape=true]
record ('proc, 'pst, 'msg) CHOAlgorithm =
	CinitState ::  "'proc $\Rightarrow$ 'pst $\Rightarrow$ 'proc $\Rightarrow$ bool"
	sendMsg ::   "'proc $\Rightarrow$ 'proc $\Rightarrow$ 'pst $\Rightarrow$ 'msg"
	CnextState :: "'proc $\Rightarrow$ 'pst $\Rightarrow$ ('proc $\Rightarrow$ 'msg message) $\Rightarrow$ 'proc $\Rightarrow$ 'pst $\Rightarrow$ bool"
\end{lstlisting}

Étant donné une fonction $rho : \mathds{N} \rightarrow \Pi \rightarrow Sleep_p \uplus States_p$, il s'agit de définir dans quels cas $rho$ peut constituer la description d'une exécution valide.
On construit donc le prédicat $HORun$ de la façon suivante :

\begin{lstlisting}[mathescape=true]
fun HOrcvMsgsQ :: "'proc $\Rightarrow$ ('proc, 'pst, 'msg) CHOAlgorithm  $\Rightarrow$ 'proc $\Rightarrow$
                         'pst procState $\Rightarrow$ 'msg message" where
	"HOrcvMsgsQ q A p (Active s) = Content (sendMsg A q p s)" |
	"HOrcvMsgsQ q A p Aslept = Nil"

definition HOrcvdMsgs :: "('proc, 'pst, 'a) CHOAlgorithm $\Rightarrow$ 'proc $\Rightarrow$
                          'proc set $\Rightarrow$ ('proc $\Rightarrow$ 'pst state)
                          $\Rightarrow$ 'proc $\Rightarrow$ 'a message" where
	"HOrcvdMsgs A p HO cfg $\equiv$
	$\lambda$ q. if q $\in$ HO then HOrcvMsgsQ q A p (cfg q) else Void"

definition CHOnextConfig where
  "CHOnextConfig A cfg HO coord cfg' $\equiv$
   $\forall$ p s.       cfg  p = Active s $\longrightarrow$
         ($\exists$ s'. cfg' p = Active s' $\wedge$
		 CnextState A p s (HOrcvdMsgs A p (HO p) cfg) (coord p) s')"

definition CHOinitConfig where
	"CHOinitConfig A rho coord $\equiv$
	$\forall$ p (n::nat) s. (n > 0 $\longrightarrow$ rho (n-1) p = Aslept)
	$\longrightarrow$ rho n p = Active s $\longrightarrow$ CinitState A p s (coord n p)"


definition CHORun where
	"CHORun A rho HOs coords $\equiv$
	CHOinitConfig A rho coords
	$\wedge$ ($\forall$ r. CHOnextConfig A (rho r) (HOs (Suc r)) (coords (Suc r)) (rho (Suc r)))"
\end{lstlisting}

Ci-dessus, les deux premières définitions définissent la fonction de réception d'un processus $p$ au round $n$, en fonction de $rho$ et de $HO(p, n)$, l'ensemble des voisins entrants de $p$.
La troisième définition est un prédicat qui vérifie si $rho$ respecte toujours la fonction de transition.
La quatrième définition est un prédicat qui vérifie si $rho$ respecte la croissance du calendrier d'activation, et si la première valeur de chaque processus $p$ vérifie $p \in Inin_p$.

\subsection{Preuve de correction de "One-Third rule"}

Il s'agit d'abord d'écrire formellement l'algorithme "One-Third rule".
L'état des processus est décrit par un tuple de deux valeurs.

\begin{lstlisting}
record 'val pstate =
	x :: "'val"
	decide :: bool
\end{lstlisting}

On définit ci-dessous les fonctions d'émission et de transition de l'algorithme "One-Third rule".

\begin{lstlisting}[mathescape=true]
definition OTRNextState where
	"OTRNextState p st msgs st' $\equiv$ 
	if (2*N) div 3 < card {q. msgs q $\neq$ Void $\and$ msgs q $\neq$ Nil}
	then
		st' = $\langle$ x = Min {v . MFR msgs v}, decide = $\exists$v. TwoThirds msgs v $\rangle$
	else
		st' = st"

definition OTRSendMsg where
  "OTRSendMsg p q st $\equiv$ x st"
\end{lstlisting}

Ci-dessus, $MFR$ signifie "most frequent received".
On démontre ensuite l'intégrité, l'accord et la terminaison.

\begin{lstlisting}[mathescape=true]
lemma OTRIntegrity:
	assumes "HORun (HOMachineToAlgorithm OTRM) rho HOs" 
	and "rho n p = Active $\langle$ x = v, decide = True $\rangle$"
shows "$\exists$ q s. x s = v $\wedge$ getInitValue rho q = Active s"
\end{lstlisting}

\begin{lstlisting}[mathescape=true]
theorem OTRAgreement:
	assumes run:"HORun (HOMachineToAlgorithm OTRM) rho HOs"
	and "rho n p = Active $\langle$ x = v, decide = True $\rangle$"
	and "rho m p' = Active $\langle$ x = w, decide = True $\rangle$"
shows "v = w"
\end{lstlisting}

\begin{lstlisting}[mathescape=true]
theorem OTRTermination:
	assumes run: "HORun (HOMachineToAlgorithm OTRM) rho HOs" 
	and pred: "HOcommGlobal OTRM HOs"
	and nonInf: "$\exists$r. rho r p $\neq$ Aslept"
shows "$\exists$ r v. rho r p = Active $\langle$ x = v, decide = True $\rangle$"
\end{lstlisting}

Ci-dessus, $HOMachineToAlgorithm~OTRM$ correspond au tuple contenant les fonctions d'émission et de transition. Le type de ce tuple est $CHOMachine$ (voir section précédente).
Ici, \emph{pred} correspond au prédicat $\mathcal{P}_{supermaj-\infty} \wedge \mathcal{P}_{S-unif-\infty}$.

\subsection{Preuve de l'algorithme SyncMod}

\begin{lstlisting}
record pstate = 
     x :: nat
     forc :: bool
     fire :: bool
    
datatype SendVal = Val nat | Bot
\end{lstlisting}

Dans cet algorithme, on décrit l'état par un tuple constitué de trois variables.
Le type $sendVal$ correspond au type des messages envoyés par les processus.
À leur premier round, ils envoient	 $Bot$. Aux rounds suivants, ils envoient leur valeur.

\begin{lstlisting}[mathescape=true]
definition readyFire where
	"readyFire msgs $\equiv$ $\forall$ p. msgs p = Void $\vee$ msgs p = Content (Val k)"

definition concordant where
	"concordant msgs v $\equiv$ $\exists$ p. msgs p = Content (Val v) $\wedge$
	($\forall$ q vv. msgs q = Content (Val vv) $\longrightarrow$ vv = v)"

definition readyForce where
	"readyForce msgs ss $\equiv$ ($\neg$ forc ss) $\wedge$ ($\forall$ p. msgs p $\neq$ Content (Val k)) $\wedge$ 
	($\exists$ p q v1 v2. msgs p = Content (Val v1) $\wedge$ msgs q = Content (Val v2) $\wedge$ v1 $\neq$ v2)"

definition SyncModNextState :: "Proc $\Rightarrow$ pstate $\Rightarrow$ (Proc $\Rightarrow$ SendVal message) $\Rightarrow$ pstate $\Rightarrow$ bool" where
	"SyncModNextState p ss msgs st $\equiv$
	fire st = (readyFire msgs $\vee$ fire ss) $\wedge$
	(if readyForce msgs ss
	then
		x st = k $\wedge$ forc st
	else
		forc ss = forc st $\wedge$ (
		if $\exists$ v. concordant msgs v
		then
			x st = (Suc ($\epsilon$ ($\lambda$ v. concordant msgs v))) mod k
		else
			x st = 1))"

definition SyncModSendMsg where
	"SyncModSendMsg p q st $\equiv$ if x st = 0 then Bot else Val (x st)"

definition SyncModInitState where 
	"SyncModInitState p st $\equiv$ x st = 0 $\wedge$ ($\neg$ forc st) $\wedge$ $\neg$ fire st"
\end{lstlisting}

Les trois premières définitions correspondent aux prédicats qui gardent les trois premières branches dans le pseudo-code de la fonction de transition.
L'opérateur $\epsilon$ est l'opérateur de Hilbert. Il vérifie $\exists x. P x \Rightarrow P (\epsilon P)$.

\begin{lstlisting}
lemma SyncModLiveness : assumes "kMod.xiNek HO xi"
	and run:"HORun (HOMachineToAlgorithm (kMod.SyncModhOMachine k)) rho HO"
	and "k > 2"
	assumes nonInf:"HOcommSchedule (kMod.SyncModhOMachine k) (Schedule rho)"
shows "kMod.liveness rho"
\end{lstlisting}

Ici, la première hypothèse correspond au prédicat $\mathcal{P}_{xi-nek}$. La troisième correspond au prédicat $\mathcal{P}_{non-inf}$.

\section{Conclusion}

Mon stage a permis d'établir un algorithme de consensus capable de fonctionner sous des hypothèses très faibles :
\begin{itemize}
	\item Seulement un processus correct, capable de faire des broadcast.
	\item Les processus n'ont pas besoin d'identifiant, ni de connaissance sur la taille du réseau.
	\item Les processus doivent s'activer en temps fini.
\end{itemize}

On pourrait renforcer davantage ce résultat en étudiant la résolubilité du consensus sous le prédicat $\mathcal{P}_{T-rooted}$ plutôt que $\mathcal{P}_{\xi-nek}$.
Cela améliorerait la tolérance aux pertes de messages.

On pourrait également s'intéresser au possibilités offertes par le model-cheking \cite{model_checking}.

\subsection{Bilan personnel - Remerciements}

Ce stage de six mois fut pour moi l'occasion d'enrichir mon expérience sur plusieurs aspects :
la plus-value la plus tangible que j'aie acquise concerne certainement mon initiation à Isabelle. Je connaissais préalablement l'assistant de preuve Coq, dont le but est similaire à Isabelle,
mais qui fonctionne de façon très différente. La maitrise de ces deux outils me donne une vision d'ensemble du domaine.
Je tiens à remercier Stephan Merz qui m'a suivi tout au long de ce stage. Il a répondu à toutes mes questions au cours de mon apprentissage de l'outil Isabelle.

Je remercie chaleureusement Bernadette Charron-Bost qui fut mon maître de stage pendant six mois.
En plus d’avoir imaginé ce sujet en fonction de mes attentes, de m’avoir guidé dans mes recherches, a fait progressé la qualité de mes
écrits, quant à la manière de rédiger un article scientifique de façon claire, précise, et conforme aux standards.


Ce stage m'a motivé pour continuer ce travail, en thèse, toujours encadré par Bernadette Charron-Bost.

\printbibliography

\section{Annexe 1 : preuve de l'algorithme "One-Third rule"}


\subsection{Intégrité}

\begin{theorem}
	Toute exécution de l'algorithme vérifie l'intégrité.
\end{theorem}
\begin{proof}
	Soit une exécution quelconque de l'algorithme. Cette exécution fixe donc $\mathds{G}$, $(\mathcal{A}_r)_{r \in \mathds{N}}$, $\Gamma$ et $(\sigma^0_p)_{p \in \Pi}$ de manière univoque.
	On montre d'abord par récurrence sur $r$ l'invariant suivant : 

	$  \forall r \in \mathds{N}, \forall p \in \mathcal{A}_{r+1}, x_p(r) \in \{\sigma^0_q, q \in \Pi\}$

\textbf{Initialisation}
	Triviale, car $p \in \mathcal{A}_1 \Rightarrow x_p(0) = \sigma^0_p$. 

\textbf{Hérédité}
	Pour un $r$ donné, on suppose $\forall p \in \mathcal{A}_{r+1}, x_p(r) \in \{\sigma^0_q, q \in \Pi\}$
	Soit $q \in \mathcal{A}_{r+2}$ . On distingue les trois cas suivants :
\begin{itemize}
	\item $q \notin \mathcal{A}_{r+1}$. Dans ce cas, $x_q(r+1) = \sigma^0_q$.
	\item $q \in \mathcal{A}_{r+1}$ et $|Sup(M_q^{r+1}) | \leq \frac{2 n}{3}$. Dans ce cas, $x_q(r+1) = x_q(r)$. L'hypothèse de récurrence permet de prouver l'invariant.
	\item $q \in \mathcal{A}_{r+1}$ et $|Sup(M_q^{r+1}) | >    \frac{2 n}{3}$. Dans ce cas, $x_q(r+1) = min \{(\widetilde{M}^{r+1}_q)^{-1} (max \widetilde{M}_q^{r+1})\}\}$.
		On applique l'hypothèse de récurrence au processus qui atteint ce minimum. Cela prouve l'invariant.

\end{itemize}

L'intégrité découle naturellement de cet invariant, car, lorsqu'un processus décide, $x_p = dec_p$.
\end{proof}

\subsection{Accord}

Soit une exécution de l'algorithme.
La preuve de l'accord des exécutions de l'algorithme est construite à partir d'une série de lemmes.

\begin{lemma}

	Si, pour $p \in \mathcal{A}_{r+1}$ , $x \in \mathcal{V}$ et $r \in \mathds{N}$, 

\begin{itemize}

	\item $| Sup(M_p^{r+1}) | > \frac{2 n}{3}$
	\item $| \{ q \in \mathcal{A}_{r+1} , x_q(r) = x \} | > \frac{2 n}{3}$

\end{itemize}

Alors $x_p(r+1) = x$.

\end{lemma}

\begin{proof}

	Soit $M$ la fonction de réception des messages de $p$ au round $r+1$. On note $M^{-1}(x)$ l'ensemble des processus ayant émis $x$, et dont le message est parvenu à $p$.

	On a
\begin{equation}
\begin{split}
	Sup(M) & = M^{-1}(x) \cup (Sup(M) \setminus M^{-1}(x)) \\
	& \subseteq M^{-1}(x) \cup \{ q \in \mathcal{A}_{r+1} , x_q(r) \neq x \}
\end{split}
\end{equation}

	Ainsi, en utilisant l'hypothèse 1, puis l'hypothèse 2, on obtient : 
\begin{equation}
\begin{split}
	\frac{2 n}{3} & < | Sup(M) | \\
		& \leq | M^{-1}(x) | + | \{ q \in \mathcal{A}_{r+1} , x_q(r) \neq x \} | \\
		& \leq | M^{-1}(x) | +  \frac{ n}{3} \\
\end{split}
\end{equation}


	Enfin, d'après l'hypothèse 2 :
\begin{equation}
\begin{split}
| M^{-1}(x) | & > \frac{ n}{3} \\
		& \geq | \{ q \in \mathcal{A}_{r+1} , x_q(r) \neq x \} | \\
		& \geq | Sup(M) \setminus M^{-1}(x) | \\
\end{split}
\end{equation}

Donc $x$ est l'élément le plus fréquent de M. Donc la ligne 10 du code assure que $x_p(r+1) = x$.

\end{proof}

\begin{lemma}\label{lem:supcons}

Toute supermajorité (ie. plus de deux tiers des processus) de valeurs se conserve :
	$$ | \{ q \in \mathcal{A}_{r+1} , x_q(r) = x \} | > 
	\frac{2 n}{3} \Rightarrow \forall k \in \mathds{N}, | \{ q \in \mathcal{A}_{r+k+1} , x_q(r+k) = x \} | > \frac{2 n}{3} . $$

\end{lemma}

\begin{proof}

	On suppose $| \{ q \in \mathcal{A}_{r+1} , x_q(r) = x \} | > \frac{2 n}{3}$. On montre par récurrence sur $k$ que
	$$| \{ q \in \mathcal{A}_{r+k+1} , x_q(r+k) = x \} | > \frac{2 n}{3}$$.

	\textbf{Initialisation :} triviale.

	\textbf{Hérédité :}
	Soit $k \in \mathds{N}$. On suppose que 
	$| \{ q \in \mathcal{A}_{r+k+1} , x_q(r+k) = x \} | > \frac{2 n}{3}$.

	Soit $p \in  \{ q \in \mathcal{A}_{r+k+1} , x_q(r+k) = x \} $. On distingue les cas suivants :

	\begin{itemize}

		\item $|HO_{actif} (p, r+k+1) | \leq \frac{2 n}{3}$. Dans ce cas, $x_p(r+k+1) = x_p(r+k) = x$.
		\item $|HO_{actif} (p, r+k+1) | > \frac{2 n}{3}$. Dans ce cas, le lemme 1 permet de montrer que $x_p(r+k+1) = x$.

	\end{itemize}

	Dans tous les cas $p \in \{ q \in \mathcal{A}_{r+k+2} , x_q(r+k+1) = x \} $. 

	Donc $| \{ q \in \mathcal{A}_{r+k+2} , x_q(r+k+1) = x \} | \geq | \{ q \in \mathcal{A}_{r+k+1} , x_q(r+k) = x \} | > \frac{2 n}{3}$.
	Cela prouve l'hérédité.
\end{proof}
\begin{lemma}
	$\forall x \in \mathcal{V}, \forall r k \in \mathds{N}, \forall p \in \mathcal{A}_r, dec_p(r) = x \Rightarrow| \{ q \in \mathcal{A}_{r+k} , x_q(r+k) = x \} | > \frac{2 n}{3}$
\end{lemma}
\begin{proof}

On montre ce lemme par récurrence sur $r$.

\textbf{Initialisation :}
	Triviale car $\mathcal{A}_0 = \emptyset$.

\textbf{Hérédité :}
	Pour $x \in \mathcal{V}, p \in \mathcal{A}_r, r \in \mathds{N}$ fixés, on suppose que :
	$$ \forall k \in \mathds{N}, dec_p(r) = x \Rightarrow| \{ q \in \mathcal{A}_{r+k} , x_q(r+k) = x \} | > \frac{2 n}{3}$$.

	On veut montrer que 
	$ \forall k \in \mathds{N}, dec_p(r+1) = x \Rightarrow| \{ q \in \mathcal{A}_{r+k+1} , x_q(r+k+1) = x \} | > \frac{2 n}{3}$.

	Soit $k \in \mathds{N}$, on suppose que $dec_p(r+1) = x$.

	\begin{itemize}

		\item Si $dec_p(r) = x$, le lemme découle de l'hypothèse de récurrence.
		\item Sinon $dec_p(r) \neq x$. Étant données les lignes 10 et 11 du pseudo-code,
			on en déduit que, au round r+1, le processus p avait reçu une fonction de réception $M_p^{r+1}$ telle que $\widetilde{M_p^{r+1}}(x) > \frac{2 n}{3}$.
			Donc $| \{ q \in \mathcal{A}_r , x_q(r) = x \} | > \frac{2 n}{3}$.
			On conclut alors en utilisant le lemme 8.2.

	\end{itemize}
\end{proof}

\begin{lemma}
	Aucune décision ne peut être en conflit avec une décision précédente.
	$$ \forall r \in \mathds{N}, k \in \mathds{N}, \forall p \in \mathcal{A}_r, q \in \mathcal{A}_{r+k},dec_p(r) = \bot \vee dec_q(r+k) = \bot \vee dec_p(r) = dec_q(m)$$.
\end{lemma}
\begin{proof}

	Si $dec_p(r) = x_1 \neq \bot$,   le lemme 8.3 montre que $|\{h \in \mathcal{A}_{r+1}, x_h(r+k) = x_1\}| > \frac{2 n}{3}$.

	Si $dec_q(r+k) = x_2 \neq \bot$,   le lemme 8.3 montre que $|\{h \in \mathcal{A}_{r+k+1}, x_h(r+k) = x_2\}|> \frac{2 n}{3}$.

Ces deux supermajorités se recoupent nécessairement, donc $x_1 = x_2$.
\end{proof}

Ce dernier lemme permet de prouver l'accord dans toute exécution de l'algorithme.

\subsection{Terminaison}
 
Pour la terminaison, on introduit tout d'abord la notion de graphe dirig\'e $G=(V,E)$ \emph{$S$-uniforme}, o\`u $S\subseteq V$ est
	un ensemble de n\oe uds de $G$ :
	$$ \forall q \in S, \  \{ p \in V : (p,q) \in E\} = S .$$
Autrement dit, l'ensemble des voisins entrants d'un n\oe ud de $S$ est $S$.

Le graphe $G$ est dit $p$-\emph{superconnect\'e} si 
	$$ | \{ q \in V : (q ,p ) \in E\} | > 2 |V|/3 .$$

On prouve alors la terminaison pour toute exécution de l'algorithme dont le graphe dynamique $ \mathds{G} $ et le calendrier des 
	activations $ {\cal A}$ vérifient  les prédicats suivants :
\begin{itemize}
	\item $\mathds{G}$ est \emph{infiniment souvent  fortement uniforme} :
		$$\forall r \in \mathds{N}, \exists t \in \mathds{N}, \exists S_t \subseteq \Pi, \  \ 
		 t > r  \wedge |S_t | > \frac{2 n}{3} \wedge  \mathds{G}_t \mbox{ est $S_t $-uniforme} .$$
	\item $\mathds{G}$ est \emph{infiniment souvent  connect\'e} :
		$$\forall r \in \mathds{N}, \forall p\in\Pi, \exists t \in \mathds{N}, \  \ 
		 t > r  \wedge \mathds{G}_t \mbox{ est $p$-superconnect\'e} .$$
		\end{itemize}
		
Par ailleurs, on consid\`ere la notion de r\'esolubilit\'e o\`u tous les processus deviennent actifs (D\'efinition~\ref{def:res}) :
	$$\exists r_0 \in \mathds{N}, \ \ \mathcal{A}_{r_0} = \Pi . $$

\begin{proof}

	À partir de ces deux prédicats, on obtient $t \geq r_0 $ et $S_t \subseteq \mathcal{A}_t = \Pi $ tel que :
	\begin{itemize}

		\item $\forall q \in S_t, \ \ HO_{actif}(q, t ) = S_t $
		\item $|S_t | > \frac{2 n}{3}$.

	\end{itemize}

	Puisque $\mathcal{A}_t = \Pi $, on en déduit que, pour tout processus $p \in S_t$, la fonction de réception $M_p^t$  v\'erifie :
	\begin{itemize}

		\item $M_p^t (q) = x_q( t-1 )$,  pour tout processus $q \in S_t$
		\item $M_p^t (q)  $ non défini sinon.

	\end{itemize}

Si $p$ et $q$ sont deux processus de $S_t$,   les deux fonctions de r\'eception
	$ M_p^t$ et $ M_q^t$ sont \'egales.
D'après la façon dont les fonctions de transition sont d\'efinies en ligne 9, on a :
	 $$ \forall p, \, q \in S_t, \ \ x_p(t) = x_q(t)   .$$
À la fin du round $t$, $S_t$ constitue donc une supermajorité de processus ayant tous une même valeur pour la variable $x$, 
	que l'on notera $\overline{x}$.
D'après le lemme~\ref{lem:supcons}, cette supermajorité se conserve aux rounds suivants.
	
Soit $p$ un processus quelconque.
Comme $\mathds{G}$ est infiniment souvent  connect\'e, il existe un round $t_p$ 
	tel que 
	$$ t_p >t \wedge | HO (p,t_p)  | > \frac{2 n}{3} . $$
Par suite, $p$ va mettre sa variable $x_p$ \`a jour (ligne 9) au round~$t_p$.

La valeur $\overline{x}$ est supermajoritaire dans le syst\`eme \`a partir du round $r$ et donc 
	$$ | \{ q\in \Pi : x_q(t'-1) \neq \overline{x}  \} | < \frac{n}{3} .$$
Il en r\'esulte que 
	$$  | \{ q\in HO(p,t')  : x_q(t'-1) =   \overline{x}  \} | >   | \{ q\in HO(p,t')  : x_q(t'-1) \neq   \overline{x}  \} | $$ 
	et le processus $p$ actualise sa variable $x_p$ \`a $\overline{x} $ d'apr\`es la fonction de transition $T_p$ 
	(ligne 9).

Le lemme~\ref{lem:supcons} et l'argument ci-dessus montrent que la variable $x_p$ se stabilise \`a la valeur
	$\overline{x} $  \`a partir du round $t_p$.
La propri\'et\'e de $p$-superconnexion prouve l'existence d'un round $s_p$ tel que
	$$ s_p > \max_{q\in\Pi} t_q \wedge | HO (p,s_p)  | > \frac{2 n}{3} . $$
D'apr\`es la fonction de transition $T_p$ (ligne 11 du code de l'algorithme), le processus $p$ va d\'ecider
	$\overline{x} $  \`a partir du round $s_p$, ce qui prouve la propri\'et\'e de terminaison.
\end{proof}

Les trois sections précédentes montrent le th\'eor\`eme suivant. 
\begin{theorem}
L'algorithme "One-Third rule" r\'esout  le consensus dans l'ensemble des graphes dynamiques 
	qui sont infiniment souvent  fortement uniformes et infiniment souvent  connect\'es. 
\end{theorem}


\end{document}
