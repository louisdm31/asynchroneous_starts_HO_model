\documentclass{article}
\usepackage{amsmath}
\usepackage[noend]{libHO/distribalgo}
\usepackage{algorithm}
\usepackage{amssymb}
\usepackage{listings}
\usepackage{amsthm}
\usepackage{dsfont}
\usepackage{stmaryrd}
\usepackage[left=2cm, right=2cm, top=2cm]{geometry}
\usepackage[utf8]{inputenc}



\newtheorem{lemma}{Lemma}[section]
\newtheorem{theorem}{Theoreme}
\newtheorem{definition}{Definition}
\usepackage{biblatex}
\addbibresource{rapport.bib}

\newcommand{\cent}{\gamma}
\newcommand{\dG}{\mathds{G}}
\newcommand{\IN}{\mathds{N}}
\newcommand{\ts}{t_{s}}
\newcommand{\tf}{t_{f}}
\newcommand{\try}{t_{t}}

\title{$k$-synchronization in distributed system}
\date{August 2020}
\author{Louis Penet de Monterno - Bernadette Charron-Bost}

\begin{document}

\maketitle

\section{Introduction}

The topic of distributed systems has focused a lot of attention in recent years.
Lots of today's digital services relies on distributed systems to improve the resilience of critical infrastructures.
A typical problem in distributed computing consists in emulating a data structure (stack, dictionary ...), or an algorithm (consensus ...) on a distributed
set of machines, such that the correctness of the considered algorithm is unaffected by the failures of some components.

There are two major frameworks in this field : synchronous and asynchronous systems (the exact definition of these terms may vary).
In an \emph{asynchronous system}, the model considers each machine as an individual state machine, which may progress independently from the others,
just like people working from home and communicating by email.
% They can send messages and check  to other machines whenever they want.
In opposition, a \emph{synchronous model} assumes the existence of a global schedule of execution.
The timeline is composed in a succession of rounds, the nodes make progress step by step \cite{closed_communic},
just like people having a meeting every day.
This document is focused on synchronous systems.

% In the framework of synchronous system, an assumption can be made

\subsection{Motivation}

In the literature, most of the proposed algorithms for synchronous system make an additional assumption.
This assumption tells that there exists a round at which every node start the execution of the algorithm.
In this context, the system is said to have \emph{synchronous starts}.
In opposition, a system where each node may start at an unpredictable round is said to have \emph{asynchronous starts}.
Since most system in the literature rely on the assumption of synchronous starts, we may wonder whether this hypothesis may be avoided.

This work may be useful in practice, since the hypothesis of synchronous starts adds an engineering constraint, which in some cases is difficult to solve.
For example, let's assume that a system needs to execute several tasks in series.
When a node ends a task, he has to start the next one, however it does not know if others nodes have finished the previous task and are ready to go on.
If each task is computed with an asynchronous-starts-tolerant algorithm, that is no longer an issue.

\subsection{Approach of this article}

The main issue that makes existing algorithms non-asynchronous-start-resilient lies in their structure :
they are composed of several alternating phases.
For example, the well-known Paxos \cite{paxos} algorithm is structured as a rotation of four phases, (named prepare,
promise, accept, accepted).
The algorithm is supposed to work properly if each phase is executed simultaneously by every nodes.

In the case of synchronous starts, the nodes always start with the first phase (prepare), and then rotate.
In that situation, the simultaneousness of each phase is guaranteed.
However, in the case of asynchronous starts, that could result in conflicting phases executed simultaneously.

To solve this problem, we need to make sure that the starting round of each node are congruent modulo $k$,
where $k$ is a parameter representing the number of phases of the target algorithm ($k=4$ in the case of Paxos).
This problem is named \emph{$k$-synchronization problem}.
The point of this article is to solve this problem.

\subsection{Proposed solution}

The goal of this document is to propose an algorithm that solves the $k$-synchronization problem.
Such an algorithm could be executed on a distributed system without synchronous starts,
an at a certain round, each node would "fire".
That would be a starting signal for the target algorithm.
The starting signals will have to satisfy the following properties :
\begin{description}
	\item[Safety :] The starting round of each node are congruent modulo $k$.
	\item[Liveness :] Every node eventually fires.
\end{description}

\subsection{Validity domain}

We would like to maximize the fault-tolerance of our systems.
In the literature, the fault-tolerance is often expressed by the maximum number of crash-failure that are expected to happen.
Hence, a $t$-resilient system is correct if at most $t$ nodes stop working.
In the Heard-Of model \cite{model_ho} which we use, the crash-failures are not defined as a "first-class" notion.
Instead, they they can be encapsulated inside the communication assumptions.
In this article, we will consider scenarios where at least one node is able to communicate with every other node.
This assumption is compliant with a failure of $n-1$ nodes, where $n$ is the total number of nodes.
Thus, this work is hopefully useful for real-life system.

\section{Heard-Of model}

Among the different synchronous models, we chose to work with the Heard-Of model.
One of the most important differentiating factor between distributed models is the way the fault-tolerance is handled.
In the literature, various possibilities have been considered : crash-failures, loss of message, messages swapped, malicious attack ...
In the Heard-Of model, the failures are supposed to happen during the communication.
The nodes are modeled by state machines (formal definition below).

At each round, each node :
\begin{itemize}
	\item Send a message according to its current state.
	\item Receives a subset of the messages that were destined to itself. The non-received messages are lost.
	\item Compute a new state, according to its previous state, and the messages it received.
\end{itemize}

\subsection{Modeling of asynchronous starts}

A system with asynchronous starts is not an open system where nodes can join at any moment.
We rather consider that every node belongs to the system from the beginning, but may not be ready yet.
A non-ready node remains passive relative to the considered algorithm, and signals its non-readiness by sending at each round, to each node a special message null.

In this document, we will make the assumption that no node can remain inactive forever.
To formally write this hypothesis, we introduce the series $(\mathcal{A}_r)_{r \in \mathds{N}}$, where, for a given execution (see the formal definition below), $\mathcal{A}_r \subseteq \Pi$ 
represents the set of active nodes at round $r$.
The "non inactive forever" hypothesis can now be written as :

$$P_{\neg-passiv-forever} \equiv \exists r \in \mathds{N}, \mathcal{A}_r = \Pi$$

Here $\Pi$ is the set of nodes.

\subsection{Definition of an algorithm}

Let $\Pi$ be a set of cardinality $n$. For each element of $\Pi$, a node is defined by the following entries :

\begin{itemize}
	\item A non-empty $States_u$ set, and an element $sleep_u \notin States_u$.
	\item A subset $Init_u \subseteq States_u$.
	\item A sending function $S_u : States_u \times \Pi \rightarrow \mathcal{M}$.
	\item A transition function $T_u : States_u \times \mathcal{X}_\Pi^{\mathcal{M}} \rightarrow States_u$,
		where $\mathcal{X}_\Pi^{\mathcal{M}}$ is the type of a partial function
		of type $\Pi \rightarrow \mathcal{M} \uplus \{null\}$.
\end{itemize}

The elements of $States_u$ are the states of $u$, and those of $Init_u$ are the possible initial values.

\begin{definition}
	An algorithm is a tuple $(States_u, Init_u, S_u, T_u)$ for each element $u \in \Pi$.
\end{definition}


\subsection{Definition of an execution}

The Heard-Of model is round based. At any round $r$, any active node $u$ run the following steps :

\begin{itemize}
	\item It emits a messages determined by its current state and the sending function.
	\item It receives a subset $HO(u,r)$ from the set of messages that were addressed to him
		\textit{during the same round}.
	\item It updates its state, according to the transition function, taking into account $HO(u,r)$.
\end{itemize}

A passive node always emits null, and remains in the $sleep_u$ state.
It can spontaneously be activated. In that case, its state moves from $sleep_u$ to $\sigma^0_u \in Init_u$.
The function $HO$ can also be viewed as a series of graph $\mathds{G}_r = (\Pi, E_r)$ where

$$(u, v) \in E_r \Leftrightarrow u \in HO(v, r)$$

The graph $\mathds{G}_r$ represents the possibilities of communications between any pair of node.
The absence of communication may mean a failure has occurred, either in the sending node, or in the connection.
This topic is out of the scope of this article, though.

An execution of an algorithm $(States_u, Init_u, S_u, T_u)$ is defined by a tuple
$(\mathds{G}, \mathcal{A}, (\sigma^0_u)_{u \in \Pi})$ where :

\begin{itemize}
	\item $\mathds{G}$ is a series of communication graph. Since a node should always be able to communicate 
		with itself, the communication graphs should always contain self-loops.
	\item $\mathcal{A}$ is the activation schedule. $\mathcal{A}_r$ is the set of active node in round $r$.
		It must be an increasing series, verifying $\mathcal{A}_0 = \emptyset$.
	\item $(\sigma^0_u)_{u \in \Pi}$ is the family of initial states for every node.
\end{itemize}

\textbf{Remarks :}

\begin{itemize}
	\item With synchronous starts, every node start during the same round : 
		$$\forall r \in \mathds{N}, \mathcal{A}_r \in \{\emptyset, \Pi\}$$

	\item The knowledge of $\mathcal{A}$ is equivalent to the knowledge of a function
		$\ts : \Pi \rightarrow \mathds{N} \cup \{\infty\}$ defined by :
		$$\ts(u) = \left \{ \begin{array}{l ll}
		  \infty & \mbox{ if  } p \notin \bigcup\limits_{r \in \mathds{N}}  \mathcal{A}_r & 
			  \mbox { ($u$ remains inactive forever) } \\
		  r  & \mbox{ if  } p \notin \mathcal{A}_{r-1} \mbox{ et } p \in \mathcal{A}_{r}  &
			  \mbox{ ($u$ is activated in round $r$)}.
		  \end{array} \right.$$

\end{itemize}

For any given execution $(\mathds{G}, \mathcal{A}, (\sigma^0_u)_{u \in \Pi})$,
the state $\Gamma_u(r)$ of any node $u$ at any round $r$ can be inductively defined :

\begin{itemize}
	\item $\forall r \in \mathds{N}, \forall u \in \Pi \setminus \mathcal{A}_{r+1}, \Gamma_u(r) = sleep_u$
	\item $\forall r \in \mathds{N}, \forall u \in \mathcal{A}_{r+1} \setminus \mathcal{A}_r,
		\Gamma_u(r) = \sigma^0_u$
	\item $\forall r \in \mathds{N}, \forall u \in \mathcal{A}_r, \Gamma_u(r+1) = T_u(\Gamma_u(r), M_u^{r+1})$
		where $M_u^r$ is the \textit{reception function} of $u$ at round $r$.
		Its type is $\mathcal{X}_\Pi^{\mathcal{M}}$.
		It is defined by
			$$ M_u^r(v) = \left \{ \begin{array}{l l}
				\mbox{null}  & \mbox{ if  } q \in (\Pi \setminus \mathcal{A}_r  ) \cap  HO(u,r)  \\
				S_q (\Gamma_q(r-1), p)  & \mbox{ if  }   q \in \mathcal{A}_r  \cap  HO(u,r) \\
				\mbox{undefined} & \mbox{ if  }   q \notin  HO(u,r) .
				\end{array} \right.$$ 
\end{itemize}

\subsection{The synchronization problem}

\begin{definition}
	Let $k > 1$ be a parameter. Let us consider an algorithm $A$ in which nodes $u$ maintains a boolean $fire_u$, which is initially $False$.
	The node $u$ fires when this parameter is set to $True$ for the first time.
	For any execution of $A$, the firing schedule $\tf : \Pi \rightarrow \mathds{N} \cup \{\infty\}$ is defined by 

	$$\tf(u) = \left \{
	\begin{array}{l l}
		\infty & \mbox{if}~\forall r \in \mathds{N}, \neg fire_u(r) \\
		Min \{r \in \mathds{N}, fire_u(r)\} & \mbox{otherwise}
	\end{array} \right.$$

	\textbf{Note :} A node $u$ which never activate verifies $\tf(u) = \infty$.
\end{definition}

\begin{definition}
	A given execution of $A$ satisfies safety relative to $k$-synchronization problem if :
	$$\exists c \in \mathds{Z}/k\mathds{Z}, \forall u \in \Pi,
	\tf(u) \neq \infty \Rightarrow \tf(u) \equiv c[k]$$
\end{definition}

\begin{definition}
	A given execution of $A$ satisfies liveness relative to $k$-synchronization problem if :
	$$\forall u \in \Pi, \tf(u) \neq \infty$$
\end{definition}

%%%%% temporaire %%%%%%%%%%
\subsection{Required hypothesis}

In order to prove the safety and the liveness of this algorithm, we need to make the following hypothesis :
there exists a node, called $\cent$, whose messages always reach their destination.
The communication graph of each round must contain a "star" whose center is always the node $\cent$.

In order to formally express this hypothesis, we write a predicate over the $HO$ function defined in a previous section :

$$\mathcal{P}_{centered} \equiv \exists \cent \in \Pi, \forall u \in \Pi, \forall r \in \mathds{N}, \cent \in HO(u,r)$$

In the predicate above, $\cent \in HO(u,r)$ informally means that $\cent$ belongs to the Heard-Of set of $u$ at round $r$. In other words, $u$ receives the message of $\cent$ at round $r$.

\section{The \textit{SynchMod} algorithm}

In the SynchMod algorithm, each node  maintains a local clock modulo $k$ with values in $\{ \overline{1}, \dots,  \overline{k} \}$.
It fires in the first round at which all the local clocks it has just heard of  are all equal to~$\overline{k} $ (line~\ref{line:fire}).
The first time a node receives discrepant clocks from its neighbors, it tries to force firing  by setting its clock to  $\overline{k} $
	(lines~\ref{line:try}-\ref{line:try+1});
	thereafter, that  just leads it to roll back its clock to 1 (line~\ref{line:tried}).
Otherwise, it receives agreed values with its own clock and then increments it by one modulo $k$ (line~\ref{line:agreed}).
Let us again stress on the fact that at each round~$t$, every active node receives the value of its local clock.
The pseudo-code of the local code of the agent~$u$ is given in Algorithm~1.

As we will see below, the difficult point in the correctness proof of the SynchMod algorithm is liveness.
However, right now, let us point out some properties of the algorithm that enable liveness.
First, if all the nodes  agree on the same value for their local clocks 
	-- in which case the system will be said to be \emph{monovalent} -- and if they are all active, 
	then the system remains monovalent forever.
Moreover, the common value of the local clocks is incremented by one at every later round and thus eventually 
	reaches the value~$\overline{k} $ (cf. Lemma \ref{lem:mono_liv}).
The key point of the algorithm and of its ``forced firing procedure'' lies in the fact that if all the communication graphs  
	contain a star centered at~$\cent$, then when  $\cent$ is active, its local clock necessarily becomes equal 
	to~$\overline{k}$, and every active node will eventually fire. 

% \textbf{Note :} The definition of an execution requires that a passive node always sends null. The algorithm itself requires that, at the round of its activation, a node always sends $\bot$.
% This is designed such that node just activated does not disturb a monovalent configuration with an initial value in $\mathds{Z}/k\mathds{Z}$.

\begin{algorithm}[htb]\label{algo:code}
\begin{distribalgo}[1]
\BLANK \INDENT{\textbf{Initialization:}}
	\STATE $\overline{c}_u \in \mathds{Z}/k\mathds{Z} \cup \{\bot\}$, initially $\bot$
	\STATE $tried_u \leftarrow false$
	\STATE $fired_u \leftarrow false$

\ENDINDENT \BLANK

\INDENT{\textbf{In each round $t$:}}
	\STATE send $\langle \overline{c}_u \rangle$ to all 
	\STATE receive incoming messages
	\IF{all the received messages are equal to $k$ and $\neg fired_u$ }
%		\STATE Fire % $fire_u \leftarrow true$
		\STATE $fired_u \leftarrow true$ \label{line:fire}
	\ENDIF
	\IF{the received messages other than $null $ and $\bot$ are all equal to $i \in \{ \overline{1}, \dots, \overline{k} \}$ }
		\STATE $\overline{c}_u \leftarrow \overline{i+1} $ \label{line:agreed}
	\ELSE \IF{$\neg tried_u $ and no received message is $k$ }
		\STATE $\overline{c}_u \leftarrow \overline{k} $  \label{line:try}
		\STATE $tried_u \leftarrow true$   \label{line:try+1}%~~~~\COMMENT{try a "forced synchronization"}
		\ELSE
		\STATE $\overline{c}_u \leftarrow \overline{1} $ \label{line:tried}% ~~~~\COMMENT{in particular, if at least one $k$ has been received, adopt 1}
	  \ENDIF
	  \ENDIF
\ENDINDENT 

\caption{{\em The SynchMod} algorithm} \label{algo:R}
\end{distribalgo}

\end{algorithm}


\subsection{Notation and preliminary lemmas}

In the rest of this section, we fix an execution $\sigma$ of the SynchMod algorithm associated to the activation 
	schedule~${\cal A}$ and a centered dynamic graph~$\dG \in {\cal G}^c$. % a definir 
Let $\cent$ denote one center of~$\dG$.	

For the correctness proof of SynchMod, we now introduce some additional definitions.
Let $S$ be any subset of $ \mathds{Z}/k\mathds{Z}$.
Round~$t$ in~$\sigma$  is said to be \emph{$S$-valent}  if $S$ is the set of the clock values of active nodes at the end of round~$t$, i.e.,
	$$ S = \{i  \in \mathds{Z}/k\mathds{Z} : \exists u \in \mathcal{A}_t, \ \overline{c}_u (t) = i \}  . $$
The system is said to be $i$-\emph{monovalent}  if the system is $\{ i\}$-valent.

Similarly to $\tf (u)$, let us define $\try (u)$  as the round number at which the node~$u$ executes line~\ref{line:try} 
	if any, and $\try (u)= \infty$ otherwise.

\begin{lemma}\label{lem:k_mono}
If $\overline{c}_\cent(t) = \overline{k} $, then the round~$t +1$ system is $\overline{1}$-monovalent.
\end{lemma}

\begin{proof}
If $\overline{c}_\cent(t) = \overline{k} $, then the node $\cent$ sends $\overline{k}$ to all nodes in round $t+1$.
Hence, any active node $u$ at round~$t+1$ receives $\overline{k}$ in this round,
	and so updates its clock $\overline{c}_u$ according to either line~\ref{line:agreed} or line~\ref{line:tried}.
In both cases, it holds that $\overline{c}_u (t+1) =\overline{1}$.
\end{proof}

\begin{lemma}\label{lem:mono_mono}
If the center $\cent$ is active in round $t$  and round~$t$ is $i$-monovalent, 
	then any subsequent round~$ t + s$ is $\overline{i+ s}$-monovalent.
\end{lemma}

\begin{proof}
The proof is by induction on $s \in \IN$.
\begin{enumerate}
		\item The base case $s=0$ corresponds to the assumption in the lemma.
		\item Induction step:  assume that the round $t+s$ is $j$-monovalent with $j = \overline{i+s} $,
			 and let~$u$ be  any active node in round~$t+s+1$.
			The center $\cent$ is active in round $t +s$, and thus sends the value $\overline{i+s}$ to~$u$
				in round~$ t+s+1$.
			Therefore, the node~$u$ can receive only this value or $\bot$, and thus updates
				$\overline{c}_u$ according to line~\ref{line:agreed}. 
			It follows that $ \overline{c}_u(t+s+1) = \overline{i+s +1}$ as required.
\end{enumerate}
\end{proof}

\begin{lemma}\label{lem:k_liv}
	If $\cent$ is active at round $t$, if $\overline{c}_\cent(t) = k$, the liveness is guaranteed.
\end{lemma}
\begin{proof}
	The lemmas \ref{lem:k_mono} and \ref{lem:mono_mono}, the system is 1-monovalent in round $t+i$,
	thus $i~mod~k$-monovalent in every $t+i$ following rounds.
	From the predicate $\mathcal{P}_{\neg-passiv-forever}$ we can obtain a round $s_{max}$ in which every node is active.
	At any round $r$ verifying $r > s_{max}$ and $r = t + i$ and $i~mod~k = 0$, the system is k-monovalent,
	and every node is active. Thus every node, including $\cent$, will send $k$.
	Thus, every node will fire.
\end{proof}
 %%%%%%%%% je me suis arretee ici.
 
\begin{lemma}\label{lem:mono_liv}
	If $\cent$ is active in round $t$, if the system is monovalent, the liveness is guaranteed.
\end{lemma}
\begin{proof}
	The lemma \ref{lem:mono_mono} guarantees that the system remains monovalent, and that it reaches a
	k-monovalent state.
	Thus $\overline{c}_\cent(t) = k$, and the lemma \ref{lem:k_liv} shows that the liveness is guaranteed.
\end{proof}

\noindent At this point, we have already proven that the liveness is guaranteed if :
\begin{itemize}
	\item the counter of $\cent$ reaches $k$.
	\item the system reaches a monovalent state.
\end{itemize}

We can summarize the state of the system at a given round in a given execution by the tuple
$$C(t) = (\overline{c}_\cent(t), \{\overline{c}_u(t), u \in \mathcal{A}_{t-1}\})$$
Hence, $C(t) = (v, S)$ means that in the current execution, the system is $S$-valent in round $t$, and the value of $\cent$ is $v$.
We note $\mathcal{F}$ this set of favorable configurations (namely configurations where $v = 1$ or $| S | = 1$).
The goal is now to prove that any execution contains at least one configuration in $\mathcal{F}$.

\begin{lemma}\label{lem:mono_bi}
	If $t$ satisfies $t > max \{\try(u) < \infty, p \in \Pi\} \cup \{\ts(u), u \in \Pi\}$,
	then the system is either monovalent or V-valent in round $t$, where $S = \{1, w\}$.
\end{lemma}
\begin{proof}
	Given any $p \in \mathcal{A}_t$, the node $u$ receives the value $\overline{c}_\cent(t-1)$ from $\cent$ in round $t$.
	\begin{itemize}
		\item If $u$ also receives a value different from $\overline{c}_\cent(t-1)$ and $\bot$.
			It cannot try a forced synchronization, since $t > \try(u)$.
			Then, the only possibility is $\overline{c}_u(t) = 1$.
		\item Otherwise, $u$ receives concordant messages, and adopts $\overline{c}_\cent(t-1)+1~mod~k$.
	\end{itemize}
\end{proof}

\subsection{Correctness proof}
\begin{lemma}\label{lem:safety}
	Any execution of SynchMod is safe relative to the $k$-synchronization problem.
\end{lemma}
\begin{proof}
	Let $u$ be the first firing node, in round $\tf(u)$.
	Since $\cent \in HO(u,\tf(u))$, the value sent by $\cent$ is necessarily $k$.
	The lemma \ref{lem:k_mono} guarantees that the system is 1-monovalent in round $\tf(u)$.
	The lemma \ref{lem:mono_mono} guarantees that for every $i > 0$, the system is $i~mod~k$-monovalent in round $\tf(u)+i$.
	Thus, if a node $v$ fires in a later round $\tf(v) > \tf(u)$, the system must have been $k$-monovalent in round $\tf(v)-1$,
	and 1-monovalent in round $\tf(v)$. Thus $\tf(u)$ and $\tf(v)$ are congruent modulo $k$.
	That proves the safety.
\end{proof}

\begin{theorem}
	The SynchMod algorithm solves the $k$-synchronization problem.
\end{theorem}
\begin{proof}
	\begin{description}
		\item[Case 1 : ] If $\try(\cent) \neq \infty$, the node $\cent$ tries once a forced synchronization, and adopts $k$.
			Thus, the liveness results from lemma \ref{lem:k_liv}.

		\item[Case 2 :] Otherwise $\try(\cent) = \infty$.
			Let $t$ be a round verifying $t > max \{\try(u) < \infty, u \in \Pi\} \cup \{\ts(u), u \in \Pi\}$.
			The lemma \ref{lem:mono_bi} shows that the system is either monovalent or bivalent in round $t$.
			\begin{description}
				\item[Sub-case 2.1] The system is monovalent. The liveness results from lemma \ref{lem:mono_liv}.
				\item[Sub-case 2.2] The current configuration is $C(t) = (w, \{1, w\})$.
					\begin{description}
						\item[Sub-sub-case 2.2.1 : ] In round $t+1$, the node $\cent$ receives at least once
							the value 1.
							Since we assumed that $\try(\cent) \neq \infty$, the only possible value for $w$ is $k$.
							Hence $C(t) \in \mathcal{F}$, the liveness results from \ref{lem:k_liv}.
						\item[Sub-sub-case 2.2.2 : ] In round $t+1$, the node $\cent$ only receives $w$.
							Hence, $\overline{c}_\cent(t+1) = w+1$.
							The next configuration is either $C(t+1) = (w+1, \{w+1\}) \in \mathcal{F}$ or $C(t+1) = (w+1, \{1, w+1\})$.
							Since the first case is favorable, we now focus on the second one.
							We can notice that the sub-case 2.2 happens again in round $t+1$.
							We can show by recurrence over $i$ that $\cent$ reaches a configuration $C(t+i) = (k, \{1, k\})$ or $C(t+i) = (k, \{k\})$ which are both favorable.
							The liveness results from lemma \ref{lem:k_liv}.
					\end{description}
				\item[Subcase 2.3 : ] The current configuration is $C(t) = (1, \{1, w\})$.
					In round $t+1$, the node $\cent$ receives its own value : 1.
					\begin{description}
						\item[Sub-sub-case 2.3.1 : ] It also receives $w$.
							Since we assumed that $\try(\cent) \neq \infty$, the only possible value for $w$ is $k$.
							Thus, the possible two configurations at round $t+1$ are $C(t+1) = (1, \{1\})$ and $C(t+1) = (1, \{1, 2\})$.
							The first one belongs to $\mathcal{F}$. The second one is tackled in sub-sub-case 2.3.2.
						\item[Sub-sub-case 2.3.2 : ] It only receives 1.
							The only possible configuration at round $t+1$ is $C(t+1) = (2, \{1, 2\})$.
							This case is tackled in case 2.2.
					\end{description}
			\end{description}
	\end{description}
	The liveness is now proved, and the safety results from lemma \ref{lem:safety}.
\end{proof}

\printbibliography

\end{document}
