\documentclass{article}
\usepackage{amsmath}
\usepackage[noend]{sources-Heard-Of/distribalgo}
\usepackage{algorithm}
\usepackage{amssymb}
\usepackage{listings}
\usepackage{amsthm}
\usepackage{dsfont}
\usepackage{stmaryrd}
\usepackage[left=2cm, right=2cm, top=2cm]{geometry}
\usepackage[utf8]{inputenc}

\newtheorem{lemma}{Lemma}[section]
\newtheorem{theorem}{Theoreme}
\newtheorem{definition}{Definition}
\usepackage{biblatex}
\addbibresource{rapport.bib}

\title{Synchronisation modulo $k$ in distributed system}
\date{August 2020}
\author{Louis Penet de Monterno - Bernadette Charron-Bost}

\begin{document}

\maketitle

\section{Introduction}

The topic of distributed systems has focused a lot of attention in recent years.
Lots of today's digital services relies on distributed systems to improve the resilience of critical infrastructure.
A typical problem in distributed computing consists in emulating a data structure, or an algorithm on a distributed
set of machines, such that the correctness of the considered algorithm is unaffected by the failures of some components.

There are two major frameworks in this field : synchronous and asynchronous systems. The exact definition of these terms may vary.
In an asynchronous system, the model considers each machine as an individual state machine, which may progress independently from the others,
just like people working from home and communicating by email.
% They can send messages and check  to other machines whenever they want.
In a synchronous system, the model assumes the existence of a global schedule of execution.
The timeline is composed in a succession of rounds, the processes make progress step by step,
just like people having a meeting every day. abo about the synchrony of the starts.
This document is focused en synchronous systems.

% In the framework of synchronous system, an assumption can be made

\subsection{Motivation}

In the litterature, most of the proposed algorithms for synchronous system make an additional assumption.
This assumption tells that there exists a round at which every process start the execution of the algorithm.
In this context, the system is said to have \emph{synchronous starts}.
In opposition, a system where each process may start at an unpredictable round is said to have \emph{asynchronous starts}.
Since most system in the litterature rely on the assumption of synchronous starts, we may wonder weather this hypothesis may be avoided.

This work may be useful in practice, since the hypothesis of synchronous starts adds an engineering constraint, which in some cases is difficult to solve.
For example, Let's assume that a system needs to execute several tasks in series.
When a processes ends a task, he has to start the next one, however it does not know if others processes have finished the previous task and are ready to go on.
If each task is computed with an asynchronous-starts-tolerant algorithm, this is no longer an issue.

\subsection{Approach of this article}

The main issue that makes existing algorithm non-asynchronous-start-resilient lies in their structure :
they are composed of several alternating phases.
For example, the well-known Paxos algorithm is structured as a rotation of four phases, (named prepare,
promise, accept, accepted).
The algorithm is supposed to work properly if each phase is executed simultaneously by every processes.

In the case of synchronous starts, the processes always start with the first phase (prepare), and then rotate.
In that situation, the simultaneousness of each phase is guaranteed.
However, in the case of asynchronous starts, that could result in conflicting phases executed simultaneously.

To solve this problem, we need to make sure that the starting round of each process are congruent modulo $k$,
where $k$ is a parameter representing the number of phase of the target algorithm.
This problem is named \emph{synchronisation modulo $k$ problem}.
The point of this article is to solve this problem.

\subsection{Proposed solution}

The goal of this document is to propose an algorithm that solves the "synchronisation modulo $k$" problem.
Such an algorithm could be executed on a distributed system without synchronous starts,
an at a certain round, each process would "fire".
That would be a starting signal for the target algorithm.
The starting signals will hopefully satisfy the above-mentioned property :
the starting round of each process are congruent modulo $k$.


\section{Heard-Of model}

\subsection{Definition of an algorithm}

Let $\Pi$ be a set of cardinality $n$. For each element of $\Pi$, a process is defined by the following entries :

\begin{itemize}
	\item A non-empty $States_p$ set, and an element $sleep_p \notin States_p$.
	\item A subset $Init_p \subseteq States_p$.
	\item A sending function $S_p : States_p \times \Pi \rightarrow \mathcal{M}$.
	\item A transition function $T_p : States_p \times \mathcal{X}_\Pi^{\mathcal{M}} \rightarrow States_p$,
		where $\mathcal{X}_\Pi^{\mathcal{M}}$ is the type of a partial function
		of type $\Pi \rightarrow \mathcal{M} \uplus \{nil\}$.
\end{itemize}

The elements of $States_p$ are the states of $p$, and those of $Init_p$ are the possible initial values.

\begin{definition}
	An algorithm is a tuple $(States_p, Init_p, S_p, T_p)$ for each element $p \in \Pi$.
\end{definition}


\subsection{Definition of an execution}

The Heard-Of model is round based. At any round $r$, any active process $p$ run the following steps :

\begin{itemize}
	\item It emits a messages determined by its current state and the sending function.
	\item It receives a subset $HO(p,r)$ from the set of messages that were addressed to him
		\textit{during the same round}.
	\item It updates its state, according to the transition function, taking into account $HO(p,r)$.
\end{itemize}

A passive process always emits $nil$, and remains in the $sleep_p$ state.
It can spontaneously be activated. In that case, its state moves from $sleep_p$ to $\sigma^0_p \in Init_p$.
The function $HO$ can also be viewed as a series of graph $\mathds{G}_r = (\Pi, E_r)$ where

$$(p, q) \in E_r \Leftrightarrow p \in HO(p, r)$$

The graph $\mathds{G}_r$ represents the possibilities of communications between any pair of process.
The absence of communication means a failure has occurred, either in the sending process, or in the connection.

An execution of an algorithm $(States_p, Init_p, S_p, T_p)$ is defined by a tuple
$(\mathds{G}, \mathcal{A}, (\sigma^0_p)_{p \in \Pi})$ where :

\begin{itemize}
	\item $\mathds{G}$ is a series of communication graph. Since a process should always be able to communicate 
		with itself, the communication graphs should always contain self-loops.
	\item $\mathcal{A}$ is the activation schedule. $\mathcal{A}_r$ is the set of active process in round $r$.
		It must be an increasing series, verifying $\mathcal{A}_0 = \emptyset$.
	\item $(\sigma^0_p)_{p \in \Pi}$ is the family of initial states for every process.
\end{itemize}

\textbf{Remarks :}

\begin{itemize}
	\item With synchronous starts, every process start during the same round : 
		$$\forall r \in \mathds{N}, \mathcal{A}_r \in \{\emptyset, \Pi\}$$

	\item The knowledge of $\mathcal{A}$ is equivalent to the knowledge of a function
		$s : \Pi \rightarrow \mathds{N} \cup \{\infty\}$ defined by :
		$$s(p) = \left \{ \begin{array}{l ll}
		  \infty & \mbox{ if  } p \notin \bigcup\limits_{r \in \mathds{N}}  \mathcal{A}_r & 
			  \mbox { ($p$ remains inactive forever) } \\
		  r  & \mbox{ if  } p \notin \mathcal{A}_{r-1} \mbox{ et } p \in \mathcal{A}_{r}  &
			  \mbox{ ($p$ is activated in round $r$)}.
		  \end{array} \right.$$

\end{itemize}

For any given execution $(\mathds{G}, \mathcal{A}, (\sigma^0_p)_{p \in \Pi})$,
the state $\Gamma_p(r)$ of any process $p$ at any round $r$ can be inductively defined :

\begin{itemize}
	\item $\forall r \in \mathds{N}, \forall p \in \Pi \setminus \mathcal{A}_{r+1}, \Gamma_p(r) = sleep_p$
	\item $\forall r \in \mathds{N}, \forall p \in \mathcal{A}_{r+1} \setminus \mathcal{A}_r,
		\Gamma_p(r) = \sigma^0_p$
	\item $\forall r \in \mathds{N}, \forall p \in \mathcal{A}_r, \Gamma_p(r+1) = T_p(\Gamma_p(r), M_p^{r+1})$
		where $M_p^r$ is the \textit{reception function} of $p$ at round $r$.
		Its type is $\mathcal{X}_\Pi^{\mathcal{M}}$.
		It is defined by
			$$ M_p^r(q) = \left \{ \begin{array}{l l}
	                         nil  & \mbox{ if  } q \in (\Pi \setminus \mathcal{A}_r  ) \cap  HO(p,r)  \\
	                         S_q (\Gamma_q(r-1), p)  & \mbox{ if  }   q \in \mathcal{A}_r  \cap  HO(p,r) \\
	                         \mbox{undefined} & \mbox{ if  }   q \notin  HO(p,r) .
	                          \end{array} \right.$$ 
\end{itemize}

\subsection{The consensus problem}

This article focuses on the consensus problem. Let $\mathcal{V}$ be a set of values. Each process has an 
initial value $v_p$. The processes execute an algorithm $A$. At each round, each process holds a decision value
$Dec_p(r) \in \mathcal{V} \uplus \{\bot\}$. If $Dec_p(r) = v$, the process $p$ is said to have decided $v$
in round $r$. If $Dec_p(r) = \bot$, the process $p$ is said to not have decided yet.

\begin{definition}
	An execution verifies integrity if 
	$$\forall r \in \mathds{N}, \forall p \in \mathcal{A}_r, Dec_p(r) \in \{\bot\} \uplus \{v_q, q \in \Pi\}$$
\end{definition}

\begin{definition}
	An execution verifies agreement if 
	$$\forall r, r' \in \mathds{N}, \forall p \in \mathcal{A}_r, \forall q \in \mathcal{A}_{r'},
	Dec_p(r) = \bot \vee Dec_q(r') = \bot \vee Dec_p(r) = Dec_q(r') $$
\end{definition}

\begin{definition}
	An execution verifies termination if
	$$ \forall p \in \bigcup\limits_{s \in \mathds{N}} \mathcal{A}_s, \exists r \in \mathds{N}, \ 
		p \in \mathcal{A}_r \wedge Dec(\Gamma_p(r)) \neq \bot .  $$
\end{definition}

\begin{definition}
	An algorithm $A$ solves consensus under the predicates $\mathcal{P}_{\mathcal{G}}$ and $\mathcal{P}_{cal}$
	if, for any execution $(\mathds{G}, \mathcal{A}, (\sigma^0_p)_{p \in \Pi})$ verifying 
	$\mathds{G} \models \mathcal{P}_{\mathcal{G}}$ and $\mathcal{A} \models \mathcal{P}_{cal}$
	verifies also integrity, termination, and agreement.
\end{definition}

\subsection{The synchronisation problem}

\begin{definition}
	Let $k > 1$ be a parameter. Let us consider an algorithm $A$ and a subset $S_{fire} \subseteq States_p$
	such as $S_{fire} \cap Init_p = \emptyset$.
	For any execution of $A$, the firing function is defined by :

	$$Fire(p) = \left \{
		\begin{array}{l l}
		\infty & \mbox{if}~\forall r \in \mathds{N}, \Gamma_p(r) \notin S_{fire} \\
		Min \{r \in \mathds{N}, \Gamma_p(r) \in S_{fire}\} & \mbox{otherwise}
		\end{array} $$
\end{definition}

\begin{definition}
	A given execution of $A$ satisfies safety relative to synchronisation modulo $k$ problem if :
	$$\exists c \in \mathds{N}, \forall p \in \bigcup\limits_{i \in \mathds{N}} \mathcal{A}_i,
	Fire(p) \neq \infty \Rightarrow Fire(p)~mod~k = c$$
\end{definition}

\begin{definition}
	A given execution of $A$ satisfies liveness relative to synchronisation modulo $k$ problem if :
	$$\forall p \in \bigcup\limits_{i \in \mathds{N}} \mathcal{A}_i, Fire(p) \neq \infty$$
\end{definition}

\section{The SyncMod algorithm}

In the SyncMod algorithm, each process has a counter value in $\mathds{Z}/k\mathds{Z}$. At each round,
they send their counter to all processes.
Then, the transition function is a case disjunction composed of four branches.

\begin{algorithm}[htb]
\begin{distribalgo}[1]
\BLANK \INDENT{\textbf{Initialisation:}}
	\STATE $x_p \in \mathds{Z}/k\mathds{Z}$
	\STATE $force_p = true$
	\STATE $fire_p = false$
	\STATE $started_p = false$

\ENDINDENT \BLANK

\INDENT{\textbf{Round $r$:}}
	\INDENT{$S_p:$}
		\IF{$started_p$}
			\STATE send $\langle x_p \rangle$ to all processes
		\ELSE
			\STATE send $\bot$ to all processes
		\ENDIF
	\ENDINDENT
	\BLANK
	\INDENT{$T_p(M):$}
		\STATE $started_p = true$
		\IF{$M(\Pi) = \{k\}$}
			\STATE $fire_p = true$ ~~~~\COMMENT{if every received message is $k$, and no $nil$, fire !}
		\ENDIF
		\IF{$M(\Pi) \setminus \{nil, \bot\} = \{v\}$}
			\STATE $x_p = v+1~mod~k$ ~~~~\COMMENT{if received message are concordant, adopt their value}
		\ELSIF{$force_p \wedge k \notin M(\Pi)$}
			\STATE $force_p = false$ ~~~~\COMMENT{if received messages are discordant,
				try a "forced synchronisation"}
			\STATE $x_p = k$
		\ELSE
			\STATE $x_p = 1$ ~~~~\COMMENT{if at least one "$k$" is received, adopt 1}
		\ENDIF
	\ENDINDENT
\ENDINDENT 
\caption{{\em SyncMod} algorithm} \label{algo:R}
\end{distribalgo}

\end{algorithm}

\subsection{Notation}

\begin{definition}
	Given $V \subseteq \mathds{Z}/k\mathds{Z}$, the system is said to be V-valent in round $r$ if :
	$$V = \{v \in \mathds{Z}/k\mathds{Z}, \exists p \in \mathcal{A}_r, x_p = v\}$$
\end{definition}

The system is said to be v-monovalent if the system is $\{v\}$-valent.

The previous definition of the $Fire$ function can be precised in the context of this algorithm.

$$Fire(p) = \left \{
	\begin{array}{l l}
	\infty & \mbox{if}~\forall r \in \mathds{N}, \Gamma_p(r) \notin S_{fire} \\
		Min \{r \in \mathds{N}, fire_p(r)\} & \mbox{otherwise}
	\end{array} $$

Similarly, a $Force$ function can be defined.

$$Force(p) = \left \{
	\begin{array}{l l}
	\infty & \mbox{if}~\forall r \in \mathds{N}, \Gamma_p(r) \notin S_{fire} \\
		Min \{r \in \mathds{N}, Force_p(r)\} & \mbox{otherwise}
	\end{array} $$

\subsection{Safety proof}

\begin{lemma}\label{lem:safety}
	Any execution of SyncMod is safe relative to the synchronisation modulo $k$ problem
	if the predicates $\mathcal{P}_{\xi-nek}$ and $\mathcal{P}_{non-inf}$ are verified.
\end{lemma}
\begin{proof}
	Let $p$ the first firing process, in round $r$.
	Since $\xi \in HO(p,r)$, the value sent by $\xi$ is necessarily $k$, thus every process have received a $k$.
	The pseudo-code is designed such that the processes adopt $1$ as soon as they receive at least one $k$.

	Now we can show by recurrence over $i$ that :

	$$\forall i \in \mathds{N}, \forall q \in \mathcal{A}_{r+i}, x_q(r+i) = i + 1~mod~k$$

	\begin{description}
		\item[Initialisation :] See above.
		\item[Heredity :] We assume that 
		$$\forall q \in \mathcal{A}_{r+i}, x_q(r+i) = i + 1~mod~k$$
	We need to show that 
	$$\forall q \in \mathcal{A}_{r+i+1}, x_q(r+i+1) = i + 2~mod~k$$
	Let $M$ be the reception function of $p$ in round $r+i+1$.
			From the recurrence hypothesis, we can deduce that $M(\Pi) \subseteq \{nil, \bot, i+1~mod~k\}$.
			Moreover $M(\xi) = i+1~mod~k$.
			Thus the second branches is executed. That ends the recurrence.
	\end{description}

	Thus, processes can only decide in rounds such that $i~mod~k = 0$, which guarantees the safety.
\end{proof}

\subsection{Liveness proof}

\begin{lemma}\label{lem:k_mono}
	If $x_\xi(t) = k$, the system is 1-monovalent in round $t+1$.
\end{lemma}
\begin{proof}
	If $x_\xi(t) = k$, the process $\xi$ sends $k$ to all processes in round $t+1$.
	Every process receives this message, thus they must execute the second or the forth branch, and adopt 1.
\end{proof}

\begin{lemma}\label{lem:mono_mono}
	If $\xi$ is active in round $s$, and the system is v-monovalent, it must be $v+i$-monovalent in round $s+i$,
	for any $i \in \mathds{N}$.
\end{lemma}
\begin{proof}
	The proof of this lemma is done by recurrence over $i$.
	\begin{description}
		\item[Initialisation :] Trivial.
		\item[Heredity :] We assume that
			$$\forall p \in \mathcal{A}_{s+i}, x_p(s+i) = v+i~mod~k$$
			We have to show that 
			$$\forall p \in \mathcal{A}_{s+i+1}, x_p(s+i+1) = v+i+1~mod~k$$
			In round $s+i+1$, processes in $\mathcal{A}_{s+i}$ send $v+i~mod~k$, whereas processes 
			in $\mathcal{A}_{s+i+1} \setminus \mathcal{A}_{s+i}$ send $\bot$.
			Moreover $\xi$ belongs to $\mathcal{A}_{s+i}$.
			Thus, every active process must execute the second branch.
			Thus the heredity holds.
	\end{description}
\end{proof}

\begin{lemma}\label{lem:k_liv}
	If $x_\xi(t) = k$ and the predicate $\mathcal{P}_{non-inf}$ is verified, the liveness is guaranteed.
\end{lemma}
\begin{proof}
	The lemmas \ref{lem:k_mono} and \ref{lem:mono_mono}, the system is 1-monovalent in round $t+i$,
	thus $i~mod~k$-monovalent in every $t+i$ following rounds.
	From the predicate $\mathcal{P}_{non-inf}$ we can obtain a round $s_{max}$ in which every process is active.
	At any round $r$ verifying $r > s_{max}$ and $r = t + i$ and $i~mod~k = 0$, the system is k-monovalent,
	and every process is active. Thus every process, including $\xi$, will send $k$.
	Thus, every process will fire.
\end{proof}

\begin{lemma}\label{lem:mono_liv}
	If $\xi$ is active in round $t$, and the system is monovalent, the liveness is guaranteed.
\end{lemma}
\begin{proof}
	The lemma \ref{lem:mono_mono} guarantees that the system remains monovalent, and that it reaches a
	k-monovalent state.
	Thus $x_\xi(t) = k$, and the lemma \ref{lem:k_liv} shows that the liveness is guaranteed.
\end{proof}

\begin{lemma}\label{lem:mono_bi}
	If $t$ satisfies $t > max \{Force(p) < \infty, p \in \Pi\} \cup \{s(p), p \in \Pi\}$,
	the system is monovalent or V-valent in round $t$, where $V = \{1, w\}$.
\end{lemma}
\begin{proof}
	Given any $p \in \mathcal{A}_t$, the process $p$ receives the value $x_\xi(t-1)$ from $\xi$ in round $t$.
	\begin{itemize}
		\item If $p$ also receives a value different from $x_\xi(t-1)$ and $\bot$, the process $p$ does not 
			execute the second branch. It does not execute the third one, either, since $t > Force(p)$.
			Then, the only possibility is $x_p(t) = 1$.
		\item Otherwise, $p$ executes the second branch, and adopts $x_\xi(t-1)+1~mod~k$.
	\end{itemize}
\end{proof}

\begin{theorem}
	The SyncMod algorithm solves the synchronisation modulo $k$ problem if the predicates $\mathcal{P}_{non-inf}$
	and $\mathcal{P}_{\xi-nek}$ are satisfied.
\end{theorem}
\begin{proof}
	\begin{description}
		\item[Case 1 : ] If $Force(\xi) = \infty$, the process $\xi$ executes once the third branch.
			Thus, the liveness results from lemma \ref{lem:k_liv}.

		\item[Case 2 :] Otherwise $Force(\xi) \neq \infty$.
			Let $t$ be a round verifying $t > max \{Force(p) < \infty, p \in \Pi\} \cup \{s(p), p \in \Pi\}$.
			The lemma \ref{lem:mono_bi} shows that the system is either monovalent or bivalent in round $t$.
			\begin{description}
				\item[Sub-case 2.1] The system is monovalent. The liveness results from lemma \ref{lem:mono_liv}.
				\item[Sub-case 2.2] The system is V-valent with $V = \{1, w\}$ and $w = x_\xi(t) \neq 1$.
					\begin{description}
						\item[Sub-sub-case 2.2.1 : ] In round $t+1$, the process $\xi$ receives at least once
							the value 1.
							This case is actually impossible, since we assumed that $Force(\xi) \neq \infty$.
						\item[Sub-sub-case 2.2.2 : ] In round $t+1$, the process $\xi$ only receives $w$.
							Hence, $x_\xi(t+1) = w+1$. The system is now either monovalent,
							or V'-valent, with $V' = \{1, w+1\}$.
							The sub-case 2.2 happens again in round $t+1$.
							We can show by recurrence over $i$ that $\xi$ reaches a state where $x_\xi(t+i) = k$.
							The liveness results from lemma \ref{lem:k_liv}.
					\end{description}
				\item[Subcase 2.3 : ] The system is V-valent with $V = \{1, w\}$ and $w = x_\xi(t) = 1$.
					In round $t+1$, the process $\xi$ receives its own value : 1.
					It cannot receives $w$, since we assumed that $Force(\xi) \neq \infty$.
					Hence, in round $t+1$, we have $x_\xi(t+1) = 2$.
					We are now brought back to sub-case 2.2.
			\end{description}
	\end{description}
	The liveness is now proved, and the safety results from lemma \ref{lem:safety}.
\end{proof}

\end{document}
