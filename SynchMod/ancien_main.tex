\documentclass{article}
\usepackage{amsmath}
\usepackage[noend]{libHO/distribalgo}
\usepackage{algorithm}
\usepackage{amssymb}
\usepackage{listings}
\usepackage{amsthm}
\usepackage{dsfont}
\usepackage{stmaryrd}
\usepackage[left=2cm, right=2cm, top=2cm]{geometry}
\usepackage[utf8]{inputenc}



\newtheorem{lemma}{Lemma}[section]
\newtheorem{theorem}{Theoreme}
\newtheorem{definition}{Definition}
\usepackage{biblatex}
\addbibresource{rapport.bib}

\newcommand{\cent}{\gamma}
\newcommand{\dG}{\mathds{G}}
\newcommand{\IN}{\mathds{N}}
\newcommand{\ts}{t_{s}}
\newcommand{\tf}{t_{f}}
\newcommand{\try}{t_{t}}

\title{$k$-synchronization in distributed system}
\date{August 2020}
\author{Louis Penet de Monterno - Bernadette Charron-Bost}

\begin{document}

\maketitle

\section{Introduction}

The topic of distributed systems has focused a lot of attention in recent years.
Lots of today's digital services relies on distributed systems to improve the resilience of critical infrastructures.
A typical problem in distributed computing consists in emulating a data structure (stack, dictionary ...), or an algorithm (consensus ...) on a distributed
set of machines, such that the correctness of the considered algorithm is unaffected by the failures of some components.

There are two major frameworks in this field : synchronous and asynchronous systems (the exact definition of these terms may vary).
In an \emph{asynchronous system}, the model considers each machine as an individual state machine, which may progress independently from the others,
just like people working from home and communicating by email.
% They can send messages and check  to other machines whenever they want.
In opposition, a \emph{synchronous model} assumes the existence of a global schedule of execution.
The timeline is composed in a succession of rounds, the nodes make progress step by step \cite{closed_communic},
just like people having a meeting every day.
This document is focused on synchronous systems.

% In the framework of synchronous system, an assumption can be made

\subsection{Motivation}

In the literature, most of the proposed algorithms for synchronous system make an additional assumption.
This assumption tells that there exists a round at which every node starts the execution of the algorithm.
In this context, the system is said to have \emph{synchronous starts}.
In opposition, a system where each node may start at an unpredictable round is said to have \emph{asynchronous starts}.
Since most system in the literature rely on the assumption of synchronous starts, we may wonder whether this hypothesis may be avoided.

This work may be useful in practice, since the hypothesis of synchronous starts adds an engineering constraint, which in some cases is difficult to solve.
For example, let's assume that a system needs to execute several tasks in series.
When a node ends a task, he has to start the next one, however it does not know if others nodes have finished the previous task and are ready to go on.
If each task is computed with an asynchronous-starts-tolerant algorithm, that is no longer an issue.

\subsection{Approach of this article}

The main issue that makes existing algorithms non-asynchronous-start-resilient lies in their structure :
they are composed of several alternating phases.
For example, the well-known Paxos \cite{paxos} algorithm is structured as a rotation of four phases, (named prepare,
promise, accept, accepted).
The algorithm is supposed to work properly if each phase is executed simultaneously by every nodes.

In the case of synchronous starts, the nodes always start with the first phase (prepare), and then rotate.
In that situation, the simultaneousness of each phase is guaranteed.
However, in the case of asynchronous starts, that could result in conflicting phases executed simultaneously.

To solve this problem, we need to make sure that the starting round of each node are congruent modulo $k$,
where $k$ is a parameter representing the number of phases of the target algorithm ($k=4$ in the case of Paxos).
This problem is named \emph{$k$-synchronization problem}.
The point of this article is to solve this problem.

\subsection{Proposed solution}

The goal of this document is to propose an algorithm that solves the $k$-synchronization problem.
Such an algorithm could be executed on a distributed system without synchronous starts,
an at a certain round, each node would "fire".
That would be a starting signal for the target algorithm.
The starting signals will have to satisfy the following properties :
\begin{description}
	\item[Safety :] The starting round of each node are congruent modulo $k$.
	\item[Liveness :] Every node eventually fires.
\end{description}

\subsection{Validity domain}

We would like to maximize the fault-tolerance of our systems.
In the literature, the fault-tolerance is often expressed by the maximum number of crash-failure that are expected to happen.
Hence, a $t$-resilient system is correct if at most $t$ nodes stop working.
In the Heard-Of model \cite{model_ho} which we use, the crash-failures are not defined as a "first-class" notion.
Instead, they they can be encapsulated inside the communication assumptions.
In this article, we will consider scenarios where at least one node is able to communicate with every other node.
This assumption is compliant with a failure of $n-1$ nodes, where $n$ is the total number of nodes.
Thus, this work is hopefully useful for real-life system.

\section{Heard-Of model}

Among the different synchronous models, we chose to work with the Heard-Of model.
One of the most important differentiating factor between distributed models is the way the fault-tolerance is handled.
In the literature, various possibilities have been considered : crash-failures, loss of message, messages swapped, malicious attack ...
In the Heard-Of model, the failures are supposed to happen during the communication.
The nodes are modeled by state machines (formal definition below).

At each round, each node :
\begin{itemize}
	\item Send a message according to its current state.
	\item Receives a subset of the messages that were destined to itself. The non-received messages are lost.
	\item Compute a new state, according to its previous state, and the messages it received.
\end{itemize}

\subsection{Modeling of asynchronous starts}

A system with asynchronous starts is not an open system where nodes can join at any moment.
We rather consider that every node belongs to the system from the beginning, but may not be ready yet.
A non-ready node remains passive relative to the considered algorithm, and signals its non-readiness by sending at each round, to each node a special message null.

In this document, we will make the assumption that no node can remain inactive forever.
To formally write this hypothesis, we introduce the series $(\mathcal{A}_r)_{r \in \mathds{N}}$, where, for a given execution (see the formal definition below), $\mathcal{A}_r \subseteq \Pi$ 
represents the set of active nodes at round $r$.
The "non inactive forever" hypothesis can now be written as

$$\exists r \in \mathds{N}, \mathcal{A}_r = \Pi.$$

Here $\Pi$ is the set of nodes.

\subsection{Definition of an algorithm}

Let $\Pi$ be a set of cardinality $n$. For each element of $\Pi$, a node is defined by the following entries :

\begin{itemize}
	\item A non-empty $States_u$ set, and an element $sleep_u \notin States_u$.
	\item A subset $Init_u \subseteq States_u$.
	\item A sending function $S_u : States_u \times \Pi \rightarrow \mathcal{M}$.
	\item A transition function $T_u : States_u \times \mathcal{X}_\Pi^{\mathcal{M}} \rightarrow States_u$,
		where $\mathcal{X}_\Pi^{\mathcal{M}}$ is the type of a partial function
		of type $\Pi \rightarrow \mathcal{M} \uplus \{null\}$.
\end{itemize}

The elements of $States_u$ are the states of $u$, and those of $Init_u$ are the possible initial values.

An \textit{algorithm} is a tuple $(States_u, Init_u, S_u, T_u)$ for each element $u \in \Pi$.


\subsection{Definition of an execution}

The Heard-Of model is round based. At any round $r$, any active node $u$ run the following steps :

\begin{itemize}
	\item It emits a messages determined by its current state and the sending function.
	\item It receives a subset $HO(u,r)$ from the set of messages that were addressed to him
		\textit{during the same round}.
	\item It updates its state, according to the transition function, taking into account $HO(u,r)$.
\end{itemize}

A passive node always emits null, and remains in the $sleep_u$ state.
It can spontaneously become active. In that case, its state moves from $sleep_u$ to $\sigma^0_u \in Init_u$.
The function $HO$ can also be viewed as a series of graph $\mathds{G}_r = (\Pi, E_r)$ where

$$(u, v) \in E_r \Leftrightarrow u \in HO(v, r)$$

The graph $\mathds{G}_r$ represents the possibilities of communications between any pair of node.
The absence of communication may mean a failure has occurred, either in the sending node, or in the connection.
This topic is out of the scope of this article, though.

An execution of an algorithm $(States_u, Init_u, S_u, T_u)$ is defined by a tuple
$(\mathds{G}, \mathcal{A}, (\sigma^0_u)_{u \in \Pi})$ where :

\begin{itemize}
	\item $\mathds{G}$ is a series of communication graph. Since a node should always be able to communicate 
		with itself, the communication graphs should always contain self-loops.
	\item $\mathcal{A}$ is the activation schedule. $\mathcal{A}_r$ is the set of active node in round $r$.
		It must be an increasing series, verifying $\mathcal{A}_0 = \emptyset$.
	\item $(\sigma^0_u)_{u \in \Pi}$ is the family of initial states for every node.
\end{itemize}

\textbf{Remarks :}

\begin{itemize}
	\item With synchronous starts, every node starts during the same round : 
		$$\forall r \in \mathds{N}, \mathcal{A}_r \in \{\emptyset, \Pi\}$$

	\item The knowledge of $\mathcal{A}$ is equivalent to the knowledge of a function
		$\ts : \Pi \rightarrow \mathds{N} \cup \{\infty\}$ defined by :
		$$\ts(u) = \left \{ \begin{array}{l ll}
		  \infty & \mbox{ if  } p \notin \bigcup\limits_{r \in \mathds{N}}  \mathcal{A}_r & 
			  \mbox { ($u$ remains inactive forever) } \\
		  r  & \mbox{ if  } p \notin \mathcal{A}_{r-1} \mbox{ et } p \in \mathcal{A}_{r}  &
			  \mbox{ ($u$ becomes active in round $r$)}.
		  \end{array} \right.$$

\end{itemize}

\subsection{The synchronization problem}

	Let $k > 1$ be a parameter. Let us consider an algorithm $A$ in which nodes $u$ maintains a boolean $fire_u$, which is initially $False$.
	The node $u$ fires when this parameter is set to $True$ for the first time.
	For any execution of $A$, the firing schedule $\tf : \Pi \rightarrow \mathds{N} \cup \{\infty\}$ is defined by 

	$$\tf(u) = \left \{
	\begin{array}{l l}
		\infty & \mbox{if}~\forall r \in \mathds{N}, \neg fire_u(r) \\
		Min \{r \in \mathds{N}, fire_u(r)\} & \mbox{otherwise}
	\end{array} \right.$$

	 A node $u$ which stays passive forever verifies $\tf(u) = \infty$.

	A given execution of $A$ satisfies \textit{safety} relative to $k$-synchronization problem if every firing node fires in rounds congruent modulo $k$, i.e.

	$$\exists c \in \mathds{Z}/k\mathds{Z}, \forall u \in \Pi, \tf(u) \neq \infty \Rightarrow \tf(u) \equiv c[k]$$

	A given execution of $A$ satisfies \textit{liveness} relative to $k$-synchronization problem if every non-passive-forever node, eventually fires, i.e.

	$$\forall u \in \bigcup\limits_{i \in \mathds{N}} \mathcal{A}_i, \tf(u) \neq \infty$$

%%%%% temporaire %%%%%%%%%%
\subsection{Required hypothesis}

In order to prove the safety and the liveness of this algorithm, we need to make the following hypothesis :
there exists a node, called $\cent$, whose messages always reach their destination.
The communication graph of each round must contain a "star" whose center is always the node $\cent$.
From this point, we will only consider executions whose communication graphs $\mathds{G}$ belongs to the family of graphs $\mathcal{G}_\mathcal{C}$ which verifies

$$\exists \cent \in \Pi, \forall u \in \Pi, \forall r \in \mathds{N}, \cent \in HO(u,r)$$

In the predicate above, $\cent \in HO(u,r)$ informally means that $\cent$ belongs to the Heard-Of set of $u$ at round $r$. In other words, $u$ receives the message of $\cent$ at round $r$.

\section{The \textit{SynchMod} algorithm}

In the SynchMod algorithm, each node  maintains a local clock modulo $k$ with values in $\{ \overline{1}, \dots,  \overline{k} \}$.
It fires in the first round at which all the local clocks it has just heard of  are all equal to~$\overline{k} $ (line~\ref{line:fire}).
The first time a node receives discrepant clocks from its neighbors, it tries to force firing  by setting its clock to  $\overline{k} $
	(lines~\ref{line:try}-\ref{line:try+1});
	thereafter, that  just leads it to roll back its clock to 1 (line~\ref{line:tried}).
Otherwise, it receives agreed values with its own clock and then increments it by one modulo $k$ (line~\ref{line:agreed}).
Let us again stress on the fact that at each round~$t$, every active node receives the value of its local clock.
The pseudo-code of the local code of the agent~$u$ is given in Algorithm~1.

As we will see below, the difficult point in the correctness proof of the SynchMod algorithm is liveness.
However, right now, let us point out some properties of the algorithm that enable liveness.
First, if all the nodes  agree on the same value for their local clocks 
	-- in which case the system will be said to be \emph{monovalent} -- and if they are all active, 
	then the system remains monovalent forever.
Moreover, the common value of the local clocks is incremented by one at every later round and thus eventually 
	reaches the value~$\overline{k} $ (cf. Lemma \ref{lem:mono_liv}).
The key point of the algorithm and of its ``forced firing procedure'' lies in the fact that if all the communication graphs  
	contain a star centered at~$\cent$, then when  $\cent$ is active, its local clock necessarily becomes equal 
	to~$\overline{k}$, and every active node will eventually fire. 

% \textbf{Note :} The definition of an execution requires that a passive node always sends null. The algorithm itself requires that, at the round of its activation, a node always sends $\bot$.
% This is designed such that node just activated does not disturb a monovalent configuration with an initial value in $\mathds{Z}/k\mathds{Z}$.

\begin{algorithm}[htb]\label{algo:code}
\begin{distribalgo}[1]
\BLANK \INDENT{\textbf{Initialization:}}
	\STATE $\overline{c}_u \in \mathds{Z}/k\mathds{Z} \cup \{\bot\}$, initially $\bot$
	\STATE $tried_u \leftarrow false$
	\STATE $fired_u \leftarrow false$

\ENDINDENT \BLANK

\INDENT{\textbf{In each round $t$:}}
	\STATE send $\langle \overline{c}_u \rangle$ to all 
	\STATE receive incoming messages
	\IF{all the received messages are equal to $\overline{k}$ and $\neg fired_u$ }
%		\STATE Fire % $fire_u \leftarrow true$
		\STATE $fired_u \leftarrow true$ \label{line:fire}
	\ENDIF
	\IF{the received messages other than $null $ and $\bot$ are all equal to $i \in \{ \overline{1}, \dots, \overline{k} \}$ }
		\STATE $\overline{c}_u \leftarrow \overline{i+1} $ \label{line:agreed}
	\ELSE \IF{$\neg tried_u $ and no received message is $\overline{k}$ }
		\STATE $\overline{c}_u \leftarrow \overline{k} $  \label{line:try}
		\STATE $tried_u \leftarrow true$   \label{line:try+1}%~~~~\COMMENT{try a "forced synchronization"}
		\ELSE
		\STATE $\overline{c}_u \leftarrow \overline{1} $ \label{line:tried}% ~~~~\COMMENT{in particular, if at least one $k$ has been received, adopt 1}
	  \ENDIF
	  \ENDIF
\ENDINDENT 

\caption{{\em The SynchMod} algorithm} \label{algo:R}
\end{distribalgo}

\end{algorithm}


\subsection{Notation and preliminary lemmas}

In the rest of this section, we fix an execution $\sigma$ of the SynchMod algorithm associated to the activation 
	schedule~${\cal A}$ and a centered dynamic graph~$\dG \in {\cal G}^c$. % a definir 
Let $\cent$ denote one center of~$\dG$.	

For the correctness proof of SynchMod, we now introduce some additional definitions.
Let $S$ be any subset of $ \mathds{Z}/k\mathds{Z}$.
Round~$t$ in~$\sigma$  is said to be \emph{$\overline{S}$-valent}  if $S$ is the set of the clock values of active nodes at the end of round~$t$, i.e.,
	$$ S = \{i  \in \mathds{Z}/k\mathds{Z} : \exists u \in \mathcal{A}_t, \ \overline{c}_u (t) = i \}  . $$
The system is said to be $\overline{i}$-\emph{monovalent}  if the system is $\{ \overline{i}\}$-valent.

Similarly to $\tf (u)$, let us define $\try (u)$  as the round number at which the node~$u$ executes line~\ref{line:try} 
	if any, and $\try (u)= \infty$ otherwise.

\begin{lemma}\label{lem:k_mono}
If $\overline{c}_\cent(t) = \overline{k} $, then the round~$t +1$ system is $\overline{1}$-monovalent.
\end{lemma}

\begin{proof}
If $\overline{c}_\cent(t) = \overline{k} $, then the node $\cent$ sends $\overline{k}$ to all nodes in round $t+1$.
Hence, any active node $u$ at round~$t+1$ receives $\overline{k}$ in this round,
	and so updates its clock $\overline{c}_u$ according to either line~\ref{line:agreed} or line~\ref{line:tried}.
In both cases, it holds that $\overline{c}_u (t+1) =\overline{1}$.
\end{proof}

\begin{lemma}\label{lem:mono_mono}
	If the center $\cent$ is active in round $t$  and round~$t$ is $\overline{i}$-monovalent, 
	then any subsequent round~$ t + s$ is $\overline{i+ s}$-monovalent.
\end{lemma}

\begin{proof}
The proof is by induction on $s \in \IN$.
\begin{enumerate}
		\item The base case $s=0$ corresponds to the assumption in the lemma.
		\item Induction step:  assume that the round $t+s$ is $\overline{i+s}$-monovalent,
			 and let~$u$ be  any active node in round~$t+s+1$.
			The center $\cent$ is active in round $t +s$, and thus sends the value $\overline{i+s}$ to~$u$
				in round~$ t+s+1$.
			Therefore, the node~$u$ can receive only this value (in addition of null and $\bot$), and thus updates
				$\overline{c}_u$ according to line~\ref{line:agreed}. 
			It follows that $ \overline{c}_u(t+s+1) = \overline{i+s +1}$ as required.
\end{enumerate}
\end{proof}

\begin{lemma}\label{lem:k_liv}
	If $\cent$ is active at round $t$, and $\overline{c}_\cent(t) = k$, then every node fires before the round $max(t, (t_s(u))_{u \in \Pi})+k$.
\end{lemma}
\begin{proof}
	The lemmas \ref{lem:k_mono} and \ref{lem:mono_mono} show that the system is $\overline{1}$-monovalent in round $t+i$,
	thus $\overline{i}$-monovalent in every $t+i$ following rounds.

	From the round $max \{t_s(u), u \in \Pi\}$, every node is active.

	From the two previous facts, we obtain that, between the round $max(t, (t_s(u))_{u \in \Pi})$ and $max(t, (t_s(u))_{u \in \Pi})+k$, there is a round $t_{mon-k}$
	such that the system is $\overline{k}$-monovalent, and every node is active.
	Then, in round $t_{mon-k}$, every node, including $\cent$, sends $k$.
	At the next round, according to line 9, every node must have fired.
\end{proof}
 
\begin{lemma}\label{lem:mono_liv}
	If $\cent$ is active in round $t$, and the system is monovalent, then every node fires before the round $max(t, (t_s(u))_{u \in \Pi})+k$.
\end{lemma}
\begin{proof}
	The lemma \ref{lem:mono_mono} guarantees that the system remains monovalent in later rounds.
	Between round $max(t, (t_s(u))_{u \in \Pi})$ and $max(t, (t_s(u))_{u \in \Pi})+k$, it must reach a $\overline{k}$-monovalent state.
	In this round, every node, including $\cent$, sends $k$.
	At the next round, according to line 9, every node must have fired.
\end{proof}

\noindent At this point, we have already proven that the liveness is guaranteed if
\begin{itemize}
	\item the counter of $\cent$ reaches $\overline{k}$.
	\item the system reaches a monovalent state.
\end{itemize}

\noindent We can summarize the state of the system at a given round in a given execution by the tuple : 
$$C(t) = (\overline{c}_\cent(t), \{\overline{c}_u(t), u \in \mathcal{A}_{t-1}\})$$
Hence, $C(t) = (\overline{v}, S)$ means that in the current execution, the system is $\overline{S}$-valent in round $t$, and the value of $\cent$ is $\overline{v}$.
%We note $\mathcal{F}$ this set of favorable configurations (namely configurations where $\overline{v} = 1$ or $| S | = 1$).
%The goal is now to prove that any execution contains at least one configuration in $\mathcal{F}$.

\begin{lemma}\label{lem:mono_bi}
	If $t$ satisfies $t > max \{\try(u) < \infty, p \in \Pi\} \cup \{\ts(u), u \in \Pi\}$,
	then the system is either monovalent or $\overline{S}$-valent in round $t$, where $S = \{1, \overline{w}\}$.
\end{lemma}
\begin{proof}
	Given any $p \in \mathcal{A}_t$, the node $u$ receives the value $\overline{c}_\cent(t-1)$ from $\cent$ in round $t$.
	\begin{itemize}
		\item If $u$ also receives a value different from $\overline{c}_\cent(t-1)$ and $\bot$.
			It cannot try a forced synchronization, since $t > \try(u)$.
			Then, according to line 17, the only possibility is $\overline{c}_u(t) = \overline{1}$.
		\item Otherwise, $u$ receives consistent messages, and adopts $\overline{c}_\cent(t-1)+\overline{1}$, according to line 11.
	\end{itemize}
\end{proof}

\begin{lemma}\label{lem:liv_main}
	If, in round $t$, the following hypothesis apply :
	\begin{itemize}
		\item every node is active,
		\item no node will ever try a forced synchronization at round $t$ or later,
		\item the node $\gamma$ never tries a forced synchronization in all the execution.
	\end{itemize}
	then every node fires before round $t+2k$.
\end{lemma}
\begin{proof}
	We note $\overline{c}_\gamma(t)$ as $\overline{w}$.
	First, we prove by induction over $i$ that

	$$\forall i \in \mathds{N}, \overline{c}_\gamma(t+i) = \overline{w+i} \wedge C(t+i) \neq (\overline{1}, \{\overline{1}, \overline{k}\}).$$

	The configuration $C(t+i) = (\overline{1}, \{\overline{1}, \overline{k}\})$ is a border-line case which has to be excluded along the induction.
	\begin{itemize}
		\item The first part of the base case results from the definition of $\overline{w}$.
		\item For the second part of the base case, let's assume that $C(t) = (\overline{1}, \{\overline{1}, \overline{k}\})$.
			We necessarily have $\overline{c}_\gamma(t-1) = \overline{k-1}$, otherwise, no node would have adopted $\overline{k}$ in round $t$.
			Then $C(t-1) \neq (\overline{1}, \{\overline{1}, \overline{k}\})$. We get a contradiction using the induction case below.
		\item For the first part of the induction case, we assume that $\overline{c}_\gamma(t+i) = \overline{w+i}$ and $C(t+i) \neq (\overline{1}, \{\overline{1}, \overline{k}\})$.
			We have to prove that $\overline{c}_\gamma(t+i+1) = \overline{w+i+1}$ and $C(t+i+1) \neq (\overline{1}, \{\overline{1}, \overline{k}\})$.

			\begin{itemize}
				\item If, in round $t+i+1$, every messages received by $\gamma$ is consistent, $\gamma$ executes line 11, that proves the first part of the induction case.
				\item Otherwise, we know from the third hypothesis that $\gamma$ does never try a forced synchronization.
					Then $tried_\gamma(t+i+1)$ is false. Moreover the condition line 13 must be false.
					That means that $\gamma$ has received a $k$. Moreover, the messages received by $\gamma$ are not consistent.
					From the lemma \ref{lem:mono_bi}, we obtain that the system is $\{\overline{1}, \overline{k}\}$-valent in round $t+i$.
					Since $C(t+i) \neq (\overline{1}, \{\overline{1}, \overline{k}\})$, we obtain that the only possible value for $\overline{c}_\gamma(t+i)$ is $\overline{k}$.
					Since the node $\gamma$ can only execute line 17, we obtain that $\overline{c}_\gamma(t+i+1) = \overline{1} = \overline{w+i+1}$.
			\end{itemize}

		\item Then, to prove that $C(t+i+1) \neq (\overline{1}, \{\overline{1}, \overline{k}\})$, we assume the opposite.
			That would mean that $w+i = \overline{k}$. Then a contradiction results from lemma \ref{lem:k_mono}.
	\end{itemize}
	Then, the system eventually reaches a configuration where $\overline{c}_\gamma(t+i) = \overline{k}$. The lemma \ref{lem:k_liv} terminates this proof.
\end{proof}

\subsection{Correctness proof}

\begin{lemma}\label{lem:saf}
	The execution $\sigma$ verifies the safety property of the $k$-synchronization problem.
\end{lemma}
\begin{proof}
	Let $u$ be the first firing node, in round $\tf(u)$.
	Since $\cent \in HO(u,\tf(u))$, the value sent by $\cent$ is necessarily $\overline{k}$.
	The lemma \ref{lem:k_mono} guarantees that the system is $\overline{1}$-monovalent in round $\tf(u)$.
	The lemma \ref{lem:mono_mono} guarantees that for every $i > 0$, the system is $\overline{i}$-monovalent in round $\tf(u)+i$.
	Thus, if a node $v$ fires in a later round $\tf(v) > \tf(u)$, the system must have been $\overline{k}$-monovalent in round $\tf(v)-1$ (see line 8),
	and $\overline{1}$-monovalent in round $\tf(v)$. Thus $\tf(u)$ and $\tf(v)$ are congruent modulo $k$.
	That proves the safety.
\end{proof}

In order to prove the liveness, we have to assume that every node becomes active in finite time.
Then, we assume that the starting schedule of the execution $\sigma$ belongs to the family of starting schedules $\mathcal{A}_\Pi$ (notation à changer) verifying

$$\exists r \in \mathds{N}, \mathcal{A}_r = \Pi.$$

\begin{lemma}\label{lem:liv}
	The execution $\sigma$ verifies the liveness property of the $k$-synchronization problem.
\end{lemma}
\begin{proof}
	If $\try(\cent) \neq \infty$, the node $\cent$ tries once a forced synchronization, and adopts $\overline{k}$.
	Thus, the liveness results from lemma \ref{lem:k_liv}.

	Otherwise $\try(\cent) = \infty$.
	Let $t$ be a round verifying $t > max \{\try(u) < \infty, u \in \Pi\} \cup \{\ts(u), u \in \Pi\}$.
	The liveness results from lemma \ref{lem:liv_main}.
\end{proof}

\begin{theorem}
	The SynchMod algorithm solves the $k$-synchronization problem if the communication graphs belongs to $\mathcal{G}_\mathcal{C}$ and the starting schedule to $\mathcal{A}_\Pi$.
\end{theorem}
\begin{proof}
	The correctness of the SynchMod algorithm results from lemma \ref{lem:liv} and \ref{lem:saf}.
\end{proof}
\printbibliography

\end{document}

